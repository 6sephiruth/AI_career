{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI DataSet Baseline Model\n",
    "\n",
    "본 문서는 HAICon을 위한 베이스라인 모델을 제공합니다.\n",
    "\n",
    "Recurrent neural network(RNN)을 이용했으며 구현 시 라이브러리는 PyTorch를 이용했습니다.\n",
    "\n",
    "GPU가 1개 있다고 가정하고 코드가 작성되었습니다.\n",
    "CPU로만 구동해보실 경우에는 모델과 batch feed 코드에서 .cuda()를 호출하지 않으시면 됩니다.\n",
    "\n",
    "구현 편의성을 위해 전역 변수가 많이 사용되었습니다.\n",
    "양해 바랍니다.\n",
    "전역 변수는 모두 대문자로 명명했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "#%reload_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 extension은 code format과 버전 출력을 위해서 사용한 것입니다. 실행하지 않아도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.8.10\n",
      "IPython 7.16.1\n",
      "\n",
      "dateutil 2.8.1\n",
      "numpy 1.19.5\n",
      "matplotlib 3.3.3\n",
      "pandas 1.1.4\n",
      "torch 1.9.0\n",
      "tqdm 4.49.0\n",
      "TaPR_pkg unknown\n",
      "cv2 4.4.0\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -p dateutil,numpy,matplotlib,pandas,torch,tqdm,TaPR_pkg,cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 목록은 실행을 위해 의존성을 가지는 파이썬 패키지입니다.\n",
    "cv2는 opencv-python 패키지를 설치하시면 됩니다.\n",
    "TaPR 사용을 위해서는 이 패키지가 필요합니다.\n",
    "\n",
    "TaPR은 평가를 위해 제공되는 패키지로 동일 폴더에 있는 \"eTaPR-21.8-py3-none-any.whl\" 파일을 설치하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "import dateutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import trange\n",
    "from TaPR_pkg import etapr\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "학습 데이터와 테스트 데이터는 CSV로 제공됩니다.\n",
    "HAI 2.0은 단일 파일이 아니라 여러 파일로 제공되기 때문에 디렉토리 안에 있는 모든 CSV를 읽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('dataset/train/train1.csv'),\n",
       " PosixPath('dataset/train/train2.csv'),\n",
       " PosixPath('dataset/train/train3.csv'),\n",
       " PosixPath('dataset/train/train4.csv'),\n",
       " PosixPath('dataset/train/train5.csv'),\n",
       " PosixPath('dataset/train/train6.csv')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATASET = sorted([x for x in Path(\"./dataset/train/\").glob(\"*.csv\")])\n",
    "TRAIN_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('dataset/test/test1.csv'),\n",
       " PosixPath('dataset/test/test2.csv'),\n",
       " PosixPath('dataset/test/test3.csv')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DATASET = sorted([x for x in Path(\"./dataset/test/\").glob(\"*.csv\")])\n",
    "TEST_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('dataset/validation/validation.csv')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_DATASET = sorted([x for x in Path(\"./dataset/validation/\").glob(\"*.csv\")])\n",
    "VALIDATION_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_csv(target):\n",
    "    return pd.read_csv(target).rename(columns=lambda x: x.strip())\n",
    "\n",
    "def dataframe_from_csvs(targets):\n",
    "    return pd.concat([dataframe_from_csv(x) for x in targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN_DF_RAW는 각각 학습 데이터를 하나의 Pandas Dataframe으로 로드한 결과입니다.\n",
    "각 필드가 가지는 값의 범위는 크게 다릅니다.\n",
    "정규화가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>C01</th>\n",
       "      <th>C02</th>\n",
       "      <th>C03</th>\n",
       "      <th>C04</th>\n",
       "      <th>C05</th>\n",
       "      <th>C06</th>\n",
       "      <th>C07</th>\n",
       "      <th>C08</th>\n",
       "      <th>C09</th>\n",
       "      <th>...</th>\n",
       "      <th>C77</th>\n",
       "      <th>C78</th>\n",
       "      <th>C79</th>\n",
       "      <th>C80</th>\n",
       "      <th>C81</th>\n",
       "      <th>C82</th>\n",
       "      <th>C83</th>\n",
       "      <th>C84</th>\n",
       "      <th>C85</th>\n",
       "      <th>C86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-11 10:00:00</td>\n",
       "      <td>-2.2642</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>-0.00087</td>\n",
       "      <td>12.01019</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92255</td>\n",
       "      <td>30.08042</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>595.06104</td>\n",
       "      <td>276.40338</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-11 10:00:01</td>\n",
       "      <td>-2.4923</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>12.56714</td>\n",
       "      <td>-0.0711</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92255</td>\n",
       "      <td>30.08423</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>531.50317</td>\n",
       "      <td>276.18634</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-11 10:00:02</td>\n",
       "      <td>-2.8460</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>-0.00072</td>\n",
       "      <td>14.48975</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91873</td>\n",
       "      <td>30.09148</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>451.06253</td>\n",
       "      <td>279.85754</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-11 10:00:03</td>\n",
       "      <td>-2.1235</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>15.93170</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91644</td>\n",
       "      <td>30.10407</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>404.38739</td>\n",
       "      <td>281.50317</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-11 10:00:04</td>\n",
       "      <td>-2.9074</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00043</td>\n",
       "      <td>16.10718</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91797</td>\n",
       "      <td>30.10331</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>382.53925</td>\n",
       "      <td>281.34039</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259195</th>\n",
       "      <td>2021-08-09 08:59:56</td>\n",
       "      <td>-2.0065</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>100.28228</td>\n",
       "      <td>0.5977</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17355</td>\n",
       "      <td>35.05434</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3178.48877</td>\n",
       "      <td>370.02679</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259196</th>\n",
       "      <td>2021-08-09 08:59:57</td>\n",
       "      <td>-2.2101</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>-0.00029</td>\n",
       "      <td>100.28228</td>\n",
       "      <td>0.5509</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16898</td>\n",
       "      <td>35.03488</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3175.36084</td>\n",
       "      <td>370.40656</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259197</th>\n",
       "      <td>2021-08-09 08:59:58</td>\n",
       "      <td>-2.3325</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00152</td>\n",
       "      <td>100.28228</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16974</td>\n",
       "      <td>35.02840</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3175.73608</td>\n",
       "      <td>368.12787</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259198</th>\n",
       "      <td>2021-08-09 08:59:59</td>\n",
       "      <td>-2.3049</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>100.26703</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16974</td>\n",
       "      <td>35.02420</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3176.61182</td>\n",
       "      <td>368.01941</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259199</th>\n",
       "      <td>2021-08-09 09:00:00</td>\n",
       "      <td>-2.2011</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>-0.00014</td>\n",
       "      <td>100.27466</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17508</td>\n",
       "      <td>35.01695</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3172.23267</td>\n",
       "      <td>367.78424</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004402 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp     C01  C02       C03      C04        C05  \\\n",
       "0       2021-07-11 10:00:00 -2.2642    0  12.26196 -0.00087   12.01019   \n",
       "1       2021-07-11 10:00:01 -2.4923    0  12.26196  0.00058   12.56714   \n",
       "2       2021-07-11 10:00:02 -2.8460    0  12.26196 -0.00072   14.48975   \n",
       "3       2021-07-11 10:00:03 -2.1235    0  12.26196  0.00101   15.93170   \n",
       "4       2021-07-11 10:00:04 -2.9074    0  12.26196  0.00043   16.10718   \n",
       "...                     ...     ...  ...       ...      ...        ...   \n",
       "259195  2021-08-09 08:59:56 -2.0065    0  12.26196  0.00051  100.28228   \n",
       "259196  2021-08-09 08:59:57 -2.2101    0  12.26196 -0.00029  100.28228   \n",
       "259197  2021-08-09 08:59:58 -2.3325    0  12.26196  0.00152  100.28228   \n",
       "259198  2021-08-09 08:59:59 -2.3049    0  12.26196  0.00058  100.26703   \n",
       "259199  2021-08-09 09:00:00 -2.2011    0  12.26196 -0.00014  100.27466   \n",
       "\n",
       "           C06       C07  C08  C09  ...      C77       C78       C79  \\\n",
       "0       0.2254  12.66931   70    1  ...  0.92255  30.08042   7.08818   \n",
       "1      -0.0711  12.66931   70    1  ...  0.92255  30.08423   7.08818   \n",
       "2       0.0051  12.66931   70    1  ...  0.91873  30.09148   7.08818   \n",
       "3       0.1842  12.66931   70    1  ...  0.91644  30.10407   7.08818   \n",
       "4       0.1842  12.66931   70    1  ...  0.91797  30.10331   7.08818   \n",
       "...        ...       ...  ...  ...  ...      ...       ...       ...   \n",
       "259195  0.5977  12.53358   70    1  ...  1.17355  35.05434  10.00000   \n",
       "259196  0.5509  12.53358   70    1  ...  1.16898  35.03488  10.00000   \n",
       "259197  0.5425  12.53358   70    1  ...  1.16974  35.02840  10.00000   \n",
       "259198  0.6266  12.53358   70    1  ...  1.16974  35.02420  10.00000   \n",
       "259199  0.7209  12.53358   70    1  ...  1.17508  35.01695  10.00000   \n",
       "\n",
       "               C80        C81  C82         C83   C84  C85   C86  \n",
       "0        595.06104  276.40338    1  1014.79321  12.0   50  3506  \n",
       "1        531.50317  276.18634    1  1014.79321  12.0   50  3493  \n",
       "2        451.06253  279.85754    1  1014.79321  12.0   50  3490  \n",
       "3        404.38739  281.50317    1  1014.79321  12.0   50  3525  \n",
       "4        382.53925  281.34039    1  1014.79321  12.0   50  3503  \n",
       "...            ...        ...  ...         ...   ...  ...   ...  \n",
       "259195  3178.48877  370.02679    1   986.05908  12.0   50   136  \n",
       "259196  3175.36084  370.40656    1   986.05908  12.0   50    89  \n",
       "259197  3175.73608  368.12787    1   986.05908  12.0   50    90  \n",
       "259198  3176.61182  368.01941    1   986.05908  12.0   50    74  \n",
       "259199  3172.23267  367.78424    1   986.05908  12.0   50   101  \n",
       "\n",
       "[1004402 rows x 87 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF_RAW = dataframe_from_csvs(TRAIN_DATASET)\n",
    "TRAIN_DF_RAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터셋은 공격을 받지 않은 평상시 데이터이고 시간을 나타내는 필드인 timestamp가 있으며, 나머지 필드는 모두 비식별화된 센서/액추에이터의 값입니다.\n",
    "정규화는 센서/액추에이터 필드만을 대상으로 해야 합니다.\n",
    "\n",
    "본 문서에서는 전체 데이터를 대상으로 이상을 탐지하므로 \"attack\" 필드만 사용하였습니다.\n",
    "\n",
    "VALID_COLUMNS_IN_TRAIN_DATASET은 학습 데이터셋에 있는 모든 센서/액추에이터 필드를 담고 있습니다.\n",
    "가끔 학습 데이터셋에 존재하지 않는 필드가 테스트 데이터셋에 존재하는 경우가 있습니다.\n",
    "학습 시 보지 못했던 필드에 대해서 테스트를 할 수 없으므로 학습 데이터셋을 기준으로 필드 이름을 얻어냈습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C01', 'C04', 'C05', 'C06', 'C07', 'C11', 'C12', 'C13', 'C14', 'C15',\n",
       "       'C16', 'C20', 'C21', 'C23', 'C24', 'C25', 'C27', 'C28', 'C30', 'C31',\n",
       "       'C32', 'C33', 'C35', 'C37', 'C40', 'C41', 'C43', 'C44', 'C45', 'C46',\n",
       "       'C47', 'C50', 'C51', 'C53', 'C56', 'C57', 'C58', 'C59', 'C60', 'C62',\n",
       "       'C65', 'C66', 'C67', 'C68', 'C70', 'C71', 'C72', 'C73', 'C74', 'C75',\n",
       "       'C76', 'C77', 'C78', 'C79', 'C80', 'C81', 'C83', 'C86'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIMESTAMP_FIELD = \"timestamp\"\n",
    "IDSTAMP_FIELD = 'id'\n",
    "ATTACK_FIELD = \"attack\"\n",
    "VALID_COLUMNS_IN_TRAIN_DATASET = TRAIN_DF_RAW.columns.drop([TIMESTAMP_FIELD, 'C02', 'C03', 'C08'  ,'C09', 'C10', 'C17', 'C18', 'C19', 'C22', 'C26', 'C29', 'C34', 'C36', 'C38', 'C39', 'C42', 'C48', 'C49', 'C52', 'C54', 'C55', 'C61', 'C63', 'C64', 'C69', 'C82', 'C84', 'C85'])\n",
    "VALID_COLUMNS_IN_TRAIN_DATASET\n",
    "# 4,  32,  45,  46,  54,  70,  71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAG_MIN과 TAG_MAX는 학습 데이터셋에서 최솟값 최댓값을 얻은 결과입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_MIN = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].min()\n",
    "TAG_MAX = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].max()\n",
    "TAG_MEAN = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].mean()\n",
    "TAG_STD = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize 함수는 Dataframe을 정규화합니다.\n",
    "정규화 방법은 최솟값, 최댓값을 이용하여 0~1의 범위에 들어오도록 하는 것입니다.\n",
    "\n",
    "가끔 값이 전혀 변하지 않는 필드가 있습니다.\n",
    "이 경우 최솟값과 최댓값이 같을 것입니다.\n",
    "본 문서에서는 이런 필드를 모두 0으로 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    ndf = df.copy()\n",
    "    for c in df.columns:\n",
    "        if TAG_MIN[c] == TAG_MAX[c]:\n",
    "            ndf[c] = df[c] - TAG_MIN[c]\n",
    "        else:\n",
    "            ndf[c] = (df[c] - TAG_MIN[c]) / (TAG_MAX[c] - TAG_MIN[c])\n",
    "    return ndf\n",
    "\n",
    "def zscore(df):\n",
    "    ndf = df.copy()\n",
    "    for c in df.columns:\n",
    "        if TAG_STD[c] == 0:\n",
    "            ndf[c] = df[c] - TAG_MEAN[c]\n",
    "        else:\n",
    "            ndf[c] = (df[c] - TAG_MEAN[c]) / TAG_STD[c]\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN_DF는 정규화를 마친 후 exponential weighted function을 통과시킨 결과입니다.\n",
    "센서에서 발생하는 noise를 smoothing 시켜주기를 기대하고 적용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C01</th>\n",
       "      <th>C04</th>\n",
       "      <th>C05</th>\n",
       "      <th>C06</th>\n",
       "      <th>C07</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>...</th>\n",
       "      <th>C74</th>\n",
       "      <th>C75</th>\n",
       "      <th>C76</th>\n",
       "      <th>C77</th>\n",
       "      <th>C78</th>\n",
       "      <th>C79</th>\n",
       "      <th>C80</th>\n",
       "      <th>C81</th>\n",
       "      <th>C83</th>\n",
       "      <th>C86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433107</td>\n",
       "      <td>0.501686</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.447955</td>\n",
       "      <td>0.816071</td>\n",
       "      <td>0.390156</td>\n",
       "      <td>0.501876</td>\n",
       "      <td>0.520480</td>\n",
       "      <td>0.449040</td>\n",
       "      <td>0.252360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138395</td>\n",
       "      <td>0.191217</td>\n",
       "      <td>0.246855</td>\n",
       "      <td>0.240561</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>0.708818</td>\n",
       "      <td>0.183693</td>\n",
       "      <td>0.169066</td>\n",
       "      <td>0.538147</td>\n",
       "      <td>0.276078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393288</td>\n",
       "      <td>0.518316</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.394629</td>\n",
       "      <td>0.816071</td>\n",
       "      <td>0.397747</td>\n",
       "      <td>0.502086</td>\n",
       "      <td>0.397507</td>\n",
       "      <td>0.450447</td>\n",
       "      <td>0.252360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124411</td>\n",
       "      <td>0.191217</td>\n",
       "      <td>0.248820</td>\n",
       "      <td>0.240561</td>\n",
       "      <td>0.194552</td>\n",
       "      <td>0.708818</td>\n",
       "      <td>0.164652</td>\n",
       "      <td>0.168297</td>\n",
       "      <td>0.538147</td>\n",
       "      <td>0.275133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.329799</td>\n",
       "      <td>0.504232</td>\n",
       "      <td>0.140385</td>\n",
       "      <td>0.405768</td>\n",
       "      <td>0.816071</td>\n",
       "      <td>0.403722</td>\n",
       "      <td>0.502096</td>\n",
       "      <td>0.471158</td>\n",
       "      <td>0.449110</td>\n",
       "      <td>0.252360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117217</td>\n",
       "      <td>0.191321</td>\n",
       "      <td>0.246492</td>\n",
       "      <td>0.238196</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>0.708818</td>\n",
       "      <td>0.139704</td>\n",
       "      <td>0.181237</td>\n",
       "      <td>0.538147</td>\n",
       "      <td>0.274871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452442</td>\n",
       "      <td>0.523321</td>\n",
       "      <td>0.154919</td>\n",
       "      <td>0.438454</td>\n",
       "      <td>0.816071</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>0.502097</td>\n",
       "      <td>0.476255</td>\n",
       "      <td>0.450447</td>\n",
       "      <td>0.252360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121013</td>\n",
       "      <td>0.191222</td>\n",
       "      <td>0.249245</td>\n",
       "      <td>0.236661</td>\n",
       "      <td>0.196509</td>\n",
       "      <td>0.708818</td>\n",
       "      <td>0.124511</td>\n",
       "      <td>0.187698</td>\n",
       "      <td>0.538147</td>\n",
       "      <td>0.277395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.322073</td>\n",
       "      <td>0.517640</td>\n",
       "      <td>0.157302</td>\n",
       "      <td>0.440088</td>\n",
       "      <td>0.816071</td>\n",
       "      <td>0.416316</td>\n",
       "      <td>0.502097</td>\n",
       "      <td>0.476510</td>\n",
       "      <td>0.450513</td>\n",
       "      <td>0.252360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130403</td>\n",
       "      <td>0.191217</td>\n",
       "      <td>0.252010</td>\n",
       "      <td>0.237531</td>\n",
       "      <td>0.196498</td>\n",
       "      <td>0.708818</td>\n",
       "      <td>0.117223</td>\n",
       "      <td>0.187446</td>\n",
       "      <td>0.538147</td>\n",
       "      <td>0.275926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259195</th>\n",
       "      <td>0.482575</td>\n",
       "      <td>0.516947</td>\n",
       "      <td>0.994085</td>\n",
       "      <td>0.519073</td>\n",
       "      <td>0.640361</td>\n",
       "      <td>0.213584</td>\n",
       "      <td>0.381813</td>\n",
       "      <td>0.458277</td>\n",
       "      <td>0.511985</td>\n",
       "      <td>0.371984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995442</td>\n",
       "      <td>0.368525</td>\n",
       "      <td>0.210206</td>\n",
       "      <td>0.404003</td>\n",
       "      <td>0.696816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996334</td>\n",
       "      <td>0.517556</td>\n",
       "      <td>0.414192</td>\n",
       "      <td>0.018821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259196</th>\n",
       "      <td>0.445001</td>\n",
       "      <td>0.509084</td>\n",
       "      <td>0.994085</td>\n",
       "      <td>0.509906</td>\n",
       "      <td>0.640361</td>\n",
       "      <td>0.212658</td>\n",
       "      <td>0.381814</td>\n",
       "      <td>0.478221</td>\n",
       "      <td>0.495688</td>\n",
       "      <td>0.371984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995509</td>\n",
       "      <td>0.368525</td>\n",
       "      <td>0.209229</td>\n",
       "      <td>0.401242</td>\n",
       "      <td>0.694925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995442</td>\n",
       "      <td>0.518710</td>\n",
       "      <td>0.414192</td>\n",
       "      <td>0.015512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259197</th>\n",
       "      <td>0.421808</td>\n",
       "      <td>0.529398</td>\n",
       "      <td>0.994085</td>\n",
       "      <td>0.507940</td>\n",
       "      <td>0.640361</td>\n",
       "      <td>0.212029</td>\n",
       "      <td>0.381814</td>\n",
       "      <td>0.438172</td>\n",
       "      <td>0.501889</td>\n",
       "      <td>0.371984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995774</td>\n",
       "      <td>0.368525</td>\n",
       "      <td>0.207451</td>\n",
       "      <td>0.401575</td>\n",
       "      <td>0.694208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995509</td>\n",
       "      <td>0.510714</td>\n",
       "      <td>0.414192</td>\n",
       "      <td>0.015419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259198</th>\n",
       "      <td>0.425455</td>\n",
       "      <td>0.519660</td>\n",
       "      <td>0.993941</td>\n",
       "      <td>0.522930</td>\n",
       "      <td>0.640361</td>\n",
       "      <td>0.212157</td>\n",
       "      <td>0.381814</td>\n",
       "      <td>0.497146</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.371984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994479</td>\n",
       "      <td>0.368525</td>\n",
       "      <td>0.203264</td>\n",
       "      <td>0.401591</td>\n",
       "      <td>0.693769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995774</td>\n",
       "      <td>0.509931</td>\n",
       "      <td>0.414192</td>\n",
       "      <td>0.014254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259199</th>\n",
       "      <td>0.443712</td>\n",
       "      <td>0.510936</td>\n",
       "      <td>0.994006</td>\n",
       "      <td>0.540597</td>\n",
       "      <td>0.640361</td>\n",
       "      <td>0.212110</td>\n",
       "      <td>0.381814</td>\n",
       "      <td>0.540904</td>\n",
       "      <td>0.503899</td>\n",
       "      <td>0.371984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993105</td>\n",
       "      <td>0.368525</td>\n",
       "      <td>0.205552</td>\n",
       "      <td>0.404897</td>\n",
       "      <td>0.693051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994479</td>\n",
       "      <td>0.509061</td>\n",
       "      <td>0.414192</td>\n",
       "      <td>0.016153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004402 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             C01       C04       C05       C06       C07       C11       C12  \\\n",
       "0       0.433107  0.501686  0.116706  0.447955  0.816071  0.390156  0.501876   \n",
       "1       0.393288  0.518316  0.121978  0.394629  0.816071  0.397747  0.502086   \n",
       "2       0.329799  0.504232  0.140385  0.405768  0.816071  0.403722  0.502096   \n",
       "3       0.452442  0.523321  0.154919  0.438454  0.816071  0.409210  0.502097   \n",
       "4       0.322073  0.517640  0.157302  0.440088  0.816071  0.416316  0.502097   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "259195  0.482575  0.516947  0.994085  0.519073  0.640361  0.213584  0.381813   \n",
       "259196  0.445001  0.509084  0.994085  0.509906  0.640361  0.212658  0.381814   \n",
       "259197  0.421808  0.529398  0.994085  0.507940  0.640361  0.212029  0.381814   \n",
       "259198  0.425455  0.519660  0.993941  0.522930  0.640361  0.212157  0.381814   \n",
       "259199  0.443712  0.510936  0.994006  0.540597  0.640361  0.212110  0.381814   \n",
       "\n",
       "             C13       C14       C15  ...       C74       C75       C76  \\\n",
       "0       0.520480  0.449040  0.252360  ...  0.138395  0.191217  0.246855   \n",
       "1       0.397507  0.450447  0.252360  ...  0.124411  0.191217  0.248820   \n",
       "2       0.471158  0.449110  0.252360  ...  0.117217  0.191321  0.246492   \n",
       "3       0.476255  0.450447  0.252360  ...  0.121013  0.191222  0.249245   \n",
       "4       0.476510  0.450513  0.252360  ...  0.130403  0.191217  0.252010   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "259195  0.458277  0.511985  0.371984  ...  0.995442  0.368525  0.210206   \n",
       "259196  0.478221  0.495688  0.371984  ...  0.995509  0.368525  0.209229   \n",
       "259197  0.438172  0.501889  0.371984  ...  0.995774  0.368525  0.207451   \n",
       "259198  0.497146  0.507812  0.371984  ...  0.994479  0.368525  0.203264   \n",
       "259199  0.540904  0.503899  0.371984  ...  0.993105  0.368525  0.205552   \n",
       "\n",
       "             C77       C78       C79       C80       C81       C83       C86  \n",
       "0       0.240561  0.194185  0.708818  0.183693  0.169066  0.538147  0.276078  \n",
       "1       0.240561  0.194552  0.708818  0.164652  0.168297  0.538147  0.275133  \n",
       "2       0.238196  0.195265  0.708818  0.139704  0.181237  0.538147  0.274871  \n",
       "3       0.236661  0.196509  0.708818  0.124511  0.187698  0.538147  0.277395  \n",
       "4       0.237531  0.196498  0.708818  0.117223  0.187446  0.538147  0.275926  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "259195  0.404003  0.696816  1.000000  0.996334  0.517556  0.414192  0.018821  \n",
       "259196  0.401242  0.694925  1.000000  0.995442  0.518710  0.414192  0.015512  \n",
       "259197  0.401575  0.694208  1.000000  0.995509  0.510714  0.414192  0.015419  \n",
       "259198  0.401591  0.693769  1.000000  0.995774  0.509931  0.414192  0.014254  \n",
       "259199  0.404897  0.693051  1.000000  0.994479  0.509061  0.414192  0.016153  \n",
       "\n",
       "[1004402 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF = normalize(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.95).mean()\n",
    "#TRAIN_DF = zscore(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.95).mean()\n",
    "\n",
    "TRAIN_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boundary_check 함수는 Pandas Dataframe에 있는 값 중 1 초과의 값이 있는지, 0 미만의 값이 있는지, NaN이 있는지 점검합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_check(df):\n",
    "    x = np.array(df, dtype=np.float32)\n",
    "    return np.any(x > 1.0), np.any(x < 0), np.any(np.isnan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_check(TRAIN_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1보다 큰 값, 0보다 작은 값, not a number가 없습니다. 정규화가 정상적으로 처리되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 모델 설정 & 데이터 입출력 정의\n",
    "\n",
    "딥러닝 학습과 추론에는 PyTorch를 사용했습니다.\n",
    "\n",
    "베이스라인 모델은 Stacked RNN(GRU cells)을 이용해서 이상을 탐지합니다.\n",
    "정상 데이터만 학습해야 하고, 정상 데이터에는 어떠한 label도 없으므로 unsupervised learning을 해야 합니다.\n",
    "\n",
    "본 모델에서는 슬라이딩 윈도우를 통해 시계열 데이터의 일부를 가져와서 해당 윈도우의 패턴을 기억하도록 했습니다.\n",
    "슬라이딩 윈도우는 90초(HAI는 1초마다 샘플링되어 있습니다)로 설정했습니다.\n",
    "\n",
    "모델의 입출력은 다음과 같이 설정했습니다.\n",
    "- 입력 : 윈도우의 앞부분 89초에 해당하는 값\n",
    "- 출력 : 윈도우의 가장 마지막 초(90번째 초)의 값\n",
    "\n",
    "이후 탐지 시에는 모델이 출력하는 값(예측값)과 실제로 들어온 값의 차를 보고 차이가 크면 이상으로 간주했습니다.\n",
    "많은 오차가 발생한다는 것은 기존에 학습 데이터셋에서 본 적이 없는 패턴이기 때문이라는 가정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_GIVEN = 59\n",
    "WINDOW_SIZE = 60\n",
    "\n",
    "\n",
    "class HaiDataset(Dataset):\n",
    "    def __init__(self, timestamps, df, stride=1, attacks=None):\n",
    "        self.ts = np.array(timestamps)\n",
    "        self.tag_values = np.array(df, dtype=np.float32)\n",
    "        self.valid_idxs = []\n",
    "        for L in trange(len(self.ts) - WINDOW_SIZE + 1):\n",
    "            R = L + WINDOW_SIZE - 1\n",
    "            if dateutil.parser.parse(self.ts[R]) - dateutil.parser.parse(\n",
    "                self.ts[L]\n",
    "            ) == timedelta(seconds=WINDOW_SIZE - 1):\n",
    "                self.valid_idxs.append(L)\n",
    "        self.valid_idxs = np.array(self.valid_idxs, dtype=np.int32)[::stride]\n",
    "        self.n_idxs = len(self.valid_idxs)\n",
    "        print(f\"# of valid windows: {self.n_idxs}\")\n",
    "        if attacks is not None:\n",
    "            self.attacks = np.array(attacks, dtype=np.float32)\n",
    "            self.with_attack = True\n",
    "        else:\n",
    "            self.with_attack = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_idxs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.valid_idxs[idx]\n",
    "        last = i + WINDOW_SIZE - 1\n",
    "        item = {\"attack\": self.attacks[last]} if self.with_attack else {}\n",
    "        item[\"ts\"] = self.ts[i + WINDOW_SIZE - 1]\n",
    "        item[\"given\"] = torch.from_numpy(self.tag_values[i : i + WINDOW_GIVEN])\n",
    "        item[\"answer\"] = torch.from_numpy(self.tag_values[last])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HaiDataset 클래스는 PyTorch의 Dataset 인터페이스를 정의한 것입니다.\n",
    "\n",
    "데이터셋을 읽을 때는 슬라이딩 윈도우가 유효한 지 점검합니다.\n",
    "정상적인 윈도우라면 원도우의 첫 시각과 마지막 시각의 차가 89초가 되어야 합니다.\n",
    "\n",
    "stride 파라미터는 슬라이딩을 할 때 크기를 의미합니다.\n",
    "전체 윈도우를 모두 학습할 수도 있지만, 시계열 데이터에서는 슬라이딩 윈도우를 1초씩 적용하면 이전 윈도우와 다음 윈도우의 값이 거의 같습니다.\n",
    "본 노트북에서는 학습을 빠르게 마치기 위해 10초씩 건너뛰면서 데이터를 추출하도록 했습니다.\n",
    "(물론 슬라이딩 크기를 1로 설정하여 모든 데이터셋을 보게 하면 더 좋을 것입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdf3eef68f8401d8b85eb2e29e12225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1004343.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# of valid windows: 334683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ts': '2021-07-11 10:00:59',\n",
       " 'given': tensor([[0.4331, 0.5017, 0.1167,  ..., 0.1691, 0.5381, 0.2761],\n",
       "         [0.3933, 0.5183, 0.1220,  ..., 0.1683, 0.5381, 0.2751],\n",
       "         [0.3298, 0.5042, 0.1404,  ..., 0.1812, 0.5381, 0.2749],\n",
       "         ...,\n",
       "         [0.4291, 0.5171, 0.1494,  ..., 0.4445, 0.5381, 0.2539],\n",
       "         [0.3044, 0.5232, 0.1492,  ..., 0.4550, 0.5381, 0.2531],\n",
       "         [0.4421, 0.5078, 0.1491,  ..., 0.4590, 0.5381, 0.2518]]),\n",
       " 'answer': tensor([3.6243e-01, 5.1686e-01, 1.4397e-01, 3.8168e-01, 8.1607e-01, 7.2305e-01,\n",
       "         6.2216e-01, 3.3827e-01, 4.3744e-01, 2.5236e-01, 2.5231e-01, 3.0503e-01,\n",
       "         4.3267e-01, 3.9412e-01, 5.8709e-01, 5.7737e-01, 4.0210e-01, 3.6142e-01,\n",
       "         9.7630e-01, 5.3105e-01, 3.3623e-01, 2.3487e-01, 9.0094e-01, 2.0972e-01,\n",
       "         2.9033e-02, 1.8386e-01, 6.4102e-01, 3.9202e-01, 1.0000e+00, 1.0000e+00,\n",
       "         4.5736e-01, 9.9884e-01, 4.7358e-01, 5.7535e-04, 4.5844e-01, 7.9845e-01,\n",
       "         1.7805e-01, 2.5224e-01, 5.0949e-01, 9.0972e-01, 7.3230e-03, 2.2613e-01,\n",
       "         1.2254e-01, 2.0755e-01, 4.1292e-01, 7.9035e-01, 1.4402e-01, 4.5567e-01,\n",
       "         1.3134e-01, 2.3775e-01, 2.6803e-01, 2.0927e-01, 2.6023e-01, 7.0882e-01,\n",
       "         1.3611e-01, 4.5193e-01, 5.3815e-01, 2.5072e-01])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAI_DATASET_TRAIN = HaiDataset(TRAIN_DF_RAW[TIMESTAMP_FIELD], TRAIN_DF, stride=3)\n",
    "HAI_DATASET_TRAIN[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋이 잘 로드되는 것을 볼 수 있습니다.\n",
    "\n",
    "모델은 3층 bidirectional GRU를 사용합니다.\n",
    "Hidden cell의 크기는 100으로 설정했습니다.\n",
    "Dropout은 사용하지 않았습니다.\n",
    "\n",
    "모델이 윈도우의 가장 첫 번째 값과 RNN의 출력을 더해서 내보내도록 skip connection(forward 메소드의 return 문 참조)을 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDDENS = 64\n",
    "N_LAYERS = 5\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "class StackedGRU(torch.nn.Module):\n",
    "    def __init__(self, n_tags):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size=n_tags,\n",
    "            hidden_size=N_HIDDENS,\n",
    "            num_layers=N_LAYERS,\n",
    "            bidirectional=True,\n",
    "            dropout=0,\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(N_HIDDENS * 2, n_tags)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(0, 1)  # (batch, seq, params) -> (seq, batch, params)\n",
    "        self.rnn.flatten_parameters()\n",
    "        outs, _ = self.rnn(x)\n",
    "        outs = self.relu(outs)\n",
    "        out = self.fc(outs[-1])\n",
    "\n",
    "        return x[0] + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedGRU(\n",
       "  (rnn): GRU(58, 64, num_layers=5, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=58, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = StackedGRU(n_tags=TRAIN_DF.shape[1])\n",
    "MODEL.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신규 모델 학습\n",
    "\n",
    "모델 학습을 직접 하려면 아래 코드를 실행하시면 됩니다.\n",
    "\n",
    "이미 학습된 모델을 로드해서 결과만 보시려면 아래 '모델 불러오기' section으로 가셔서 실행을 이어가시면 됩니다.\n",
    "\n",
    "Loss function은 MSE를 선택했고, optimizer는 AdamW(Loshchilov & Hutter, \"Decoupled Weight Decay Regularization\", ICLR 2019)를 사용합니다.\n",
    "\n",
    "학습 시 epoch loss가 가장 좋았던 모델의 파라미터를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, batch_size, n_epochs):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    epochs = trange(n_epochs, desc=\"training\")\n",
    "    best = {\"loss\": sys.float_info.max}\n",
    "    loss_history = []\n",
    "    for e in epochs:\n",
    "        epoch_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            given = batch[\"given\"].cuda()\n",
    "            guess = model(given)\n",
    "            answer = batch[\"answer\"].cuda()\n",
    "            loss = loss_fn(answer, guess)\n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        loss_history.append(epoch_loss)\n",
    "        epochs.set_postfix_str(f\"loss: {epoch_loss:.6f}\")\n",
    "        if epoch_loss < best[\"loss\"]:\n",
    "            best[\"state\"] = model.state_dict()\n",
    "            best[\"loss\"] = epoch_loss\n",
    "            best[\"epoch\"] = e + 1\n",
    "    return best, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 32 에포크 진행했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b4fa21967d475d8ff7987875c3a40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training', max=250.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "MODEL.train()\n",
    "BEST_MODEL, LOSS_HISTORY = train(HAI_DATASET_TRAIN, MODEL, BATCH_SIZE, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL[\"loss\"], BEST_MODEL[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pt\", \"wb\") as f:\n",
    "    torch.save(\n",
    "        {\n",
    "            \"state\": BEST_MODEL[\"state\"],\n",
    "            \"best_epoch\": BEST_MODEL[\"epoch\"],\n",
    "            \"loss_history\": LOSS_HISTORY,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기\n",
    "\n",
    "이미 학습된 모델 파라미터와 training loss 기록을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pt\", \"rb\") as f:\n",
    "    SAVED_MODEL = torch.load(f)\n",
    "\n",
    "MODEL.load_state_dict(SAVED_MODEL[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(\"Training Loss Graph\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(SAVED_MODEL[\"loss_history\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델을 이용한 탐지\n",
    "\n",
    "검증 데이터셋을 불러와서 모델에 입력으로 주고 예측값과 실제값의 차를 얻어봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋에 대해서도 만들어둔 함수를 이용해서 점검해봅니다.\n",
    "Not a number가 있는지 점검하는 것이 주요 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DF_RAW = dataframe_from_csvs(VALIDATION_DATASET)\n",
    "VALIDATION_DF_RAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋도 정상 데이터셋의 최솟값, 최댓값을 이용해서 정규화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DF = normalize(VALIDATION_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET])\n",
    "#VALIDATION_DF = zscore(VALIDATION_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_check(VALIDATION_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격 데이터셋에서는 확실히 정상 데이터의 최솟값과 최댓값을 벗어나는 값이 나타나고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAI_DATASET_VALIDATION = HaiDataset(\n",
    "    VALIDATION_DF_RAW[TIMESTAMP_FIELD], VALIDATION_DF, attacks=VALIDATION_DF_RAW[ATTACK_FIELD]\n",
    ")\n",
    "HAI_DATASET_VALIDATION[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋에 대해서도 PyTorch Dataset 인스턴스를 만들었습니다.\n",
    "모든 데이터 포인트에 대해 점검해야 하므로 학습 데이터 때와는 다르게 슬라이딩의 크기는 1로 두어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dataset, model, batch_size):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    ts, dist, att = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            given = batch[\"given\"].cuda()\n",
    "            answer = batch[\"answer\"].cuda()\n",
    "            guess = model(given)\n",
    "            ts.append(np.array(batch[\"ts\"]))\n",
    "            dist.append(torch.abs(answer - guess).cpu().numpy())\n",
    "            try:\n",
    "                att.append(np.array(batch[\"attack\"]))\n",
    "            except:\n",
    "                att.append(np.zeros(batch_size))\n",
    "            \n",
    "    return (\n",
    "        np.concatenate(ts),\n",
    "        np.concatenate(dist),\n",
    "        np.concatenate(att),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference 함수는 데이터를 순차적으로 보면서 모델이 예측한 값과 실제 값의 차를 구해서 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MODEL.eval()\n",
    "CHECK_TS, CHECK_DIST, CHECK_ATT = inference(HAI_DATASET_VALIDATION, MODEL, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK_DIST는 검증 데이터셋 전체 시간대에 대해 모든 필드의 |예측값 - 실제값|을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_DIST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격 여부 판단을 위해 같은 시각에서 전체 필드가 산출하는 차의 평균을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 눈으로 확인하기 위해 그래프를 그려보겠습니다.\n",
    "piece 파라미터는 그래프를 몇 개로 나누어 그릴지를 결정합니다.\n",
    "세세한 결과를 보고 싶을 경우 숫자를 늘리면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_graph(xs, att, piece=2, THRESHOLD=None):\n",
    "    l = xs.shape[0]\n",
    "    chunk = l // piece\n",
    "    fig, axs = plt.subplots(piece, figsize=(20, 4 * piece))\n",
    "    for i in range(piece):\n",
    "        L = i * chunk\n",
    "        R = min(L + chunk, l)\n",
    "        xticks = range(L, R)\n",
    "        axs[i].plot(xticks, xs[L:R])\n",
    "        if len(xs[L:R]) > 0:\n",
    "            peak = max(xs[L:R])\n",
    "            axs[i].plot(xticks, att[L:R] * peak * 0.3)\n",
    "        if THRESHOLD!=None:\n",
    "            axs[i].axhline(y=THRESHOLD, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.026\n",
    "check_graph(ANOMALY_SCORE, CHECK_ATT, piece=2, THRESHOLD=THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주황색 선은 공격 위치를 나타내고, 파란색 선은 (평균) 오차의 크기를 나타냅니다.\n",
    "전반적으로 공격 위치에서 큰 오차를 보이고 있습니다.\n",
    "\n",
    "임의의 threshold(빨간색 선)가 넘어갈 경우 공격으로 간주합니다.\n",
    "공격은 1로 정상은 0으로 표기합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_labels(distance, threshold):\n",
    "    xs = np.zeros_like(distance)\n",
    "    xs[distance > threshold] = 1\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프를 보면 대략 0.022를 기준으로 설정할 수 있을 것으로 보입니다.\n",
    "여러 번의 실험을 통해 정밀하게 임계치를 선택하면 더 좋은 결과를 얻을 수 있을 것으로 예상합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = put_labels(ANOMALY_SCORE, THRESHOLD)\n",
    "LABELS, LABELS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답지(ATTACK_LABELS)도 동일하게 추출합니다.\n",
    "검증 데이터셋에 공격 여부를 나타내는 필드에는 정상을 0으로 공격을 1로 표기하고 있습니다.\n",
    "위에 정의한 put_labels 함수를 이용해서 0.5를 기준으로 같은 방식으로 TaPR을 위한 label을 붙여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_LABELS = put_labels(np.array(VALIDATION_DF_RAW[ATTACK_FIELD]), threshold=0.5)\n",
    "ATTACK_LABELS, ATTACK_LABELS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "탐지 모델이 윈도우 방식으로 판단을 진행했기 때문에,\n",
    "1. 첫 시작의 몇 초는 판단을 내릴 수 없고\n",
    "2. 데이터셋 중간에 시간이 연속되지 않는 구간에 대해서는 판단을 내릴 수 없습니다.\n",
    "\n",
    "위에서 보시는 바와 같이 정답에 비해 얻어낸 label의 수가 적습니다.\n",
    "\n",
    "아래의 fill_blank 함수는 빈칸을 채워줍니다.\n",
    "빈 곳은 정상(0) 표기하고 나머지는 모델의 판단(정상 0, 비정상 1)을 채워줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_blank(check_ts, labels, total_ts):\n",
    "    def ts_generator():\n",
    "        for t in total_ts:\n",
    "            yield dateutil.parser.parse(t)\n",
    "\n",
    "    def label_generator():\n",
    "        for t, label in zip(check_ts, labels):\n",
    "            yield dateutil.parser.parse(t), label\n",
    "\n",
    "    g_ts = ts_generator()\n",
    "    g_label = label_generator()\n",
    "    final_labels = []\n",
    "\n",
    "    try:\n",
    "        current = next(g_ts)\n",
    "        ts_label, label = next(g_label)\n",
    "        while True:\n",
    "            if current > ts_label:\n",
    "                ts_label, label = next(g_label)\n",
    "                continue\n",
    "            elif current < ts_label:\n",
    "                final_labels.append(0)\n",
    "                current = next(g_ts)\n",
    "                continue\n",
    "            final_labels.append(label)\n",
    "            current = next(g_ts)\n",
    "            ts_label, label = next(g_label)\n",
    "    except StopIteration:\n",
    "        return np.array(final_labels, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FINAL_LABELS = fill_blank(CHECK_TS, LABELS, np.array(VALIDATION_DF_RAW[TIMESTAMP_FIELD]))\n",
    "FINAL_LABELS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가\n",
    "\n",
    "평가는 TaPR을 사용합니다.\n",
    "정답(ATTACK_LABELS)과 모델의 결과(FINAL_LABELS)의 길이가 같은지 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaPR 점수를 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaPR = etapr.evaluate_haicon(anomalies=ATTACK_LABELS, predictions=FINAL_LABELS)\n",
    "print(f\"F1: {TaPR['f1']:.3f} (TaP: {TaPR['TaP']:.3f}, TaR: {TaPR['TaR']:.3f})\")\n",
    "print(f\"# of detected anomalies: {len(TaPR['Detected_Anomalies'])}\")\n",
    "print(f\"Detected anomalies: {TaPR['Detected_Anomalies']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터셋 예측\n",
    "학습 데이터셋과 검증 데이터셋을 이용해 만든 모델로 테스트 데이터셋 결과를 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF_RAW = dataframe_from_csvs(TEST_DATASET)\n",
    "TEST_DF_RAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터셋도 정상 데이터셋의 최솟값, 최댓값을 이용해서 정규화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF = normalize(TEST_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.95).mean()\n",
    "# TEST_DF = zscore(TEST_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.95).mean()\n",
    "\n",
    "TEST_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터셋에 대해서도 만들어둔 함수를 이용해서 점검해봅니다.\n",
    "Not a number가 있는지 점검하는 것이 주요 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_check(TEST_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAI_DATASET_TEST = HaiDataset(\n",
    "    TEST_DF_RAW[TIMESTAMP_FIELD], TEST_DF, attacks=None\n",
    ")\n",
    "HAI_DATASET_VALIDATION[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터셋에 대해서도 PyTorch Dataset 인스턴스를 만들었습니다. 모든 데이터 포인트에 대해 점검해야 하므로 검증 데이터 때와 마찬가지로 슬라이딩의 크기는 1로 두어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference 함수로 데이터를 순차적으로 보면서 모델이 예측한 값과 실제 값의 차를 구해서 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MODEL.eval()\n",
    "CHECK_TS, CHECK_DIST, CHECK_ATT = inference(HAI_DATASET_TEST, MODEL, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격 여부 판단을 위해 같은 시각에서 전체 필드가 산출하는 차의 평균을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 눈으로 확인하기 위해 그래프를 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_graph(ANOMALY_SCORE, CHECK_ATT, piece=3, THRESHOLD=THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋을 이용해 찾은 threshold를 이용해 공격 여부를 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = put_labels(ANOMALY_SCORE, THRESHOLD)\n",
    "LABELS, LABELS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측한 결과를 제출양식에 맞춰 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./dataset/sample_submission.csv')\n",
    "submission.index = submission['timestamp']\n",
    "submission.loc[CHECK_TS,'attack'] = LABELS\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측한 결과를 저장하여 제출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('1번.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaPR = etapr.evaluate_haicon(anomalies=ATTACK_LABELS, predictions=FINAL_LABELS)\n",
    "print(f\"F1: {TaPR['f1']:.3f} (TaP: {TaPR['TaP']:.3f}, TaR: {TaPR['TaR']:.3f})\")\n",
    "print(f\"# of detected anomalies: {len(TaPR['Detected_Anomalies'])}\")\n",
    "print(f\"Detected anomalies: {TaPR['Detected_Anomalies']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Copyright 2020. ETRI부설국가보안기술연구소. All rights reserved.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
