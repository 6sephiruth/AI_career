{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "import dateutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import trange\n",
    "from TaPR_pkg import etapr\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = sorted([x for x in Path(\"dataset/train/\").glob(\"*.csv\")])\n",
    "TEST_DATASET = sorted([x for x in Path(\"dataset/test/\").glob(\"*.csv\")])\n",
    "VALIDATION_DATASET = sorted([x for x in Path(\"dataset/validation/\").glob(\"*.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_csv(target):\n",
    "    return pd.read_csv(target).rename(columns=lambda x: x.strip())\n",
    "\n",
    "def dataframe_from_csvs(targets):\n",
    "    return pd.concat([dataframe_from_csv(x) for x in targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN_DF_RAW는 각각 학습 데이터를 하나의 Pandas Dataframe으로 로드한 결과입니다.\n",
    "각 필드가 가지는 값의 범위는 크게 다릅니다.\n",
    "정규화가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>C01</th>\n",
       "      <th>C02</th>\n",
       "      <th>C03</th>\n",
       "      <th>C04</th>\n",
       "      <th>C05</th>\n",
       "      <th>C06</th>\n",
       "      <th>C07</th>\n",
       "      <th>C08</th>\n",
       "      <th>C09</th>\n",
       "      <th>...</th>\n",
       "      <th>C77</th>\n",
       "      <th>C78</th>\n",
       "      <th>C79</th>\n",
       "      <th>C80</th>\n",
       "      <th>C81</th>\n",
       "      <th>C82</th>\n",
       "      <th>C83</th>\n",
       "      <th>C84</th>\n",
       "      <th>C85</th>\n",
       "      <th>C86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-11 10:00:00</td>\n",
       "      <td>-2.2642</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>-0.00087</td>\n",
       "      <td>12.01019</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92255</td>\n",
       "      <td>30.08042</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>595.06104</td>\n",
       "      <td>276.40338</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-11 10:00:01</td>\n",
       "      <td>-2.4923</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>12.56714</td>\n",
       "      <td>-0.0711</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92255</td>\n",
       "      <td>30.08423</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>531.50317</td>\n",
       "      <td>276.18634</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-11 10:00:02</td>\n",
       "      <td>-2.8460</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>-0.00072</td>\n",
       "      <td>14.48975</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91873</td>\n",
       "      <td>30.09148</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>451.06253</td>\n",
       "      <td>279.85754</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-11 10:00:03</td>\n",
       "      <td>-2.1235</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>15.93170</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91644</td>\n",
       "      <td>30.10407</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>404.38739</td>\n",
       "      <td>281.50317</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-11 10:00:04</td>\n",
       "      <td>-2.9074</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00043</td>\n",
       "      <td>16.10718</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>12.66931</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91797</td>\n",
       "      <td>30.10331</td>\n",
       "      <td>7.08818</td>\n",
       "      <td>382.53925</td>\n",
       "      <td>281.34039</td>\n",
       "      <td>1</td>\n",
       "      <td>1014.79321</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>3503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259195</th>\n",
       "      <td>2021-08-09 08:59:56</td>\n",
       "      <td>-2.0065</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>100.28228</td>\n",
       "      <td>0.5977</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17355</td>\n",
       "      <td>35.05434</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3178.48877</td>\n",
       "      <td>370.02679</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259196</th>\n",
       "      <td>2021-08-09 08:59:57</td>\n",
       "      <td>-2.2101</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>-0.00029</td>\n",
       "      <td>100.28228</td>\n",
       "      <td>0.5509</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16898</td>\n",
       "      <td>35.03488</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3175.36084</td>\n",
       "      <td>370.40656</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259197</th>\n",
       "      <td>2021-08-09 08:59:58</td>\n",
       "      <td>-2.3325</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00152</td>\n",
       "      <td>100.28228</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16974</td>\n",
       "      <td>35.02840</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3175.73608</td>\n",
       "      <td>368.12787</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259198</th>\n",
       "      <td>2021-08-09 08:59:59</td>\n",
       "      <td>-2.3049</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>100.26703</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16974</td>\n",
       "      <td>35.02420</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3176.61182</td>\n",
       "      <td>368.01941</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259199</th>\n",
       "      <td>2021-08-09 09:00:00</td>\n",
       "      <td>-2.2011</td>\n",
       "      <td>0</td>\n",
       "      <td>12.26196</td>\n",
       "      <td>-0.00014</td>\n",
       "      <td>100.27466</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>12.53358</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17508</td>\n",
       "      <td>35.01695</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>3172.23267</td>\n",
       "      <td>367.78424</td>\n",
       "      <td>1</td>\n",
       "      <td>986.05908</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004402 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp     C01  C02       C03      C04        C05  \\\n",
       "0       2021-07-11 10:00:00 -2.2642    0  12.26196 -0.00087   12.01019   \n",
       "1       2021-07-11 10:00:01 -2.4923    0  12.26196  0.00058   12.56714   \n",
       "2       2021-07-11 10:00:02 -2.8460    0  12.26196 -0.00072   14.48975   \n",
       "3       2021-07-11 10:00:03 -2.1235    0  12.26196  0.00101   15.93170   \n",
       "4       2021-07-11 10:00:04 -2.9074    0  12.26196  0.00043   16.10718   \n",
       "...                     ...     ...  ...       ...      ...        ...   \n",
       "259195  2021-08-09 08:59:56 -2.0065    0  12.26196  0.00051  100.28228   \n",
       "259196  2021-08-09 08:59:57 -2.2101    0  12.26196 -0.00029  100.28228   \n",
       "259197  2021-08-09 08:59:58 -2.3325    0  12.26196  0.00152  100.28228   \n",
       "259198  2021-08-09 08:59:59 -2.3049    0  12.26196  0.00058  100.26703   \n",
       "259199  2021-08-09 09:00:00 -2.2011    0  12.26196 -0.00014  100.27466   \n",
       "\n",
       "           C06       C07  C08  C09  ...      C77       C78       C79  \\\n",
       "0       0.2254  12.66931   70    1  ...  0.92255  30.08042   7.08818   \n",
       "1      -0.0711  12.66931   70    1  ...  0.92255  30.08423   7.08818   \n",
       "2       0.0051  12.66931   70    1  ...  0.91873  30.09148   7.08818   \n",
       "3       0.1842  12.66931   70    1  ...  0.91644  30.10407   7.08818   \n",
       "4       0.1842  12.66931   70    1  ...  0.91797  30.10331   7.08818   \n",
       "...        ...       ...  ...  ...  ...      ...       ...       ...   \n",
       "259195  0.5977  12.53358   70    1  ...  1.17355  35.05434  10.00000   \n",
       "259196  0.5509  12.53358   70    1  ...  1.16898  35.03488  10.00000   \n",
       "259197  0.5425  12.53358   70    1  ...  1.16974  35.02840  10.00000   \n",
       "259198  0.6266  12.53358   70    1  ...  1.16974  35.02420  10.00000   \n",
       "259199  0.7209  12.53358   70    1  ...  1.17508  35.01695  10.00000   \n",
       "\n",
       "               C80        C81  C82         C83   C84  C85   C86  \n",
       "0        595.06104  276.40338    1  1014.79321  12.0   50  3506  \n",
       "1        531.50317  276.18634    1  1014.79321  12.0   50  3493  \n",
       "2        451.06253  279.85754    1  1014.79321  12.0   50  3490  \n",
       "3        404.38739  281.50317    1  1014.79321  12.0   50  3525  \n",
       "4        382.53925  281.34039    1  1014.79321  12.0   50  3503  \n",
       "...            ...        ...  ...         ...   ...  ...   ...  \n",
       "259195  3178.48877  370.02679    1   986.05908  12.0   50   136  \n",
       "259196  3175.36084  370.40656    1   986.05908  12.0   50    89  \n",
       "259197  3175.73608  368.12787    1   986.05908  12.0   50    90  \n",
       "259198  3176.61182  368.01941    1   986.05908  12.0   50    74  \n",
       "259199  3172.23267  367.78424    1   986.05908  12.0   50   101  \n",
       "\n",
       "[1004402 rows x 87 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF_RAW = dataframe_from_csvs(TRAIN_DATASET)\n",
    "TRAIN_DF_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>C01</th>\n",
       "      <th>C02</th>\n",
       "      <th>C03</th>\n",
       "      <th>C04</th>\n",
       "      <th>C05</th>\n",
       "      <th>C06</th>\n",
       "      <th>C07</th>\n",
       "      <th>C08</th>\n",
       "      <th>C09</th>\n",
       "      <th>...</th>\n",
       "      <th>C77</th>\n",
       "      <th>C78</th>\n",
       "      <th>C79</th>\n",
       "      <th>C80</th>\n",
       "      <th>C81</th>\n",
       "      <th>C82</th>\n",
       "      <th>C83</th>\n",
       "      <th>C84</th>\n",
       "      <th>C85</th>\n",
       "      <th>C86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1004402</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1004402.0</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1004402.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1004402.0</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1004402.0</td>\n",
       "      <td>1.004402e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1004402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2021-07-19 00:32:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.068788e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.224465e+01</td>\n",
       "      <td>-3.072510e-05</td>\n",
       "      <td>6.507154e+01</td>\n",
       "      <td>4.457734e-01</td>\n",
       "      <td>1.259976e+01</td>\n",
       "      <td>7.448029e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105578e+00</td>\n",
       "      <td>3.386906e+01</td>\n",
       "      <td>4.192900e+00</td>\n",
       "      <td>2.202201e+03</td>\n",
       "      <td>3.662623e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.009977e+03</td>\n",
       "      <td>1.200010e+01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.126177e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.973782e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.322091e-01</td>\n",
       "      <td>1.644198e-03</td>\n",
       "      <td>4.124122e+01</td>\n",
       "      <td>9.490236e-01</td>\n",
       "      <td>2.312396e-01</td>\n",
       "      <td>4.972919e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.886521e-02</td>\n",
       "      <td>2.897106e+00</td>\n",
       "      <td>3.445795e+00</td>\n",
       "      <td>1.329775e+03</td>\n",
       "      <td>6.061224e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.981555e+01</td>\n",
       "      <td>1.718555e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.693609e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.627100e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198730e+01</td>\n",
       "      <td>-4.253000e-02</td>\n",
       "      <td>2.685500e-01</td>\n",
       "      <td>-2.146700e+00</td>\n",
       "      <td>1.203892e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.532800e-01</td>\n",
       "      <td>2.815872e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.112275e+01</td>\n",
       "      <td>2.309570e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.900452e+02</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.120000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.689100e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.210938e+01</td>\n",
       "      <td>-1.090000e-03</td>\n",
       "      <td>1.500092e+01</td>\n",
       "      <td>-9.020000e-02</td>\n",
       "      <td>1.253358e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053010e+00</td>\n",
       "      <td>3.083306e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.533513e+02</td>\n",
       "      <td>3.180339e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.775195e+02</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.158600e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.226196e+01</td>\n",
       "      <td>-7.000000e-05</td>\n",
       "      <td>9.403381e+01</td>\n",
       "      <td>4.304000e-01</td>\n",
       "      <td>1.266931e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111760e+00</td>\n",
       "      <td>3.548735e+01</td>\n",
       "      <td>5.327940e+00</td>\n",
       "      <td>3.176862e+03</td>\n",
       "      <td>3.652344e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.007838e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.560500e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.226959e+01</td>\n",
       "      <td>1.010000e-03</td>\n",
       "      <td>1.005112e+02</td>\n",
       "      <td>8.929000e-01</td>\n",
       "      <td>1.275681e+01</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165160e+00</td>\n",
       "      <td>3.602524e+01</td>\n",
       "      <td>6.862630e+00</td>\n",
       "      <td>3.184745e+03</td>\n",
       "      <td>4.146954e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.030605e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.376000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.286000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.686249e+01</td>\n",
       "      <td>4.051000e-02</td>\n",
       "      <td>1.008774e+02</td>\n",
       "      <td>3.148700e+00</td>\n",
       "      <td>1.281139e+01</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088320e+00</td>\n",
       "      <td>3.805496e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>3.190000e+03</td>\n",
       "      <td>4.997649e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.121855e+03</td>\n",
       "      <td>1.714934e+01</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.299300e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp           C01        C02           C03  \\\n",
       "count               1004402  1.004402e+06  1004402.0  1.004402e+06   \n",
       "unique              1004402           NaN        NaN           NaN   \n",
       "top     2021-07-19 00:32:26           NaN        NaN           NaN   \n",
       "freq                      1           NaN        NaN           NaN   \n",
       "mean                    NaN -2.068788e+00        0.0  1.224465e+01   \n",
       "std                     NaN  9.973782e-01        0.0  1.322091e-01   \n",
       "min                     NaN -4.627100e+00        0.0  1.198730e+01   \n",
       "25%                     NaN -2.689100e+00        0.0  1.210938e+01   \n",
       "50%                     NaN -2.158600e+00        0.0  1.226196e+01   \n",
       "75%                     NaN -1.560500e+00        0.0  1.226959e+01   \n",
       "max                     NaN  8.286000e-01        0.0  1.686249e+01   \n",
       "\n",
       "                 C04           C05           C06           C07           C08  \\\n",
       "count   1.004402e+06  1.004402e+06  1.004402e+06  1.004402e+06  1.004402e+06   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean   -3.072510e-05  6.507154e+01  4.457734e-01  1.259976e+01  7.448029e+01   \n",
       "std     1.644198e-03  4.124122e+01  9.490236e-01  2.312396e-01  4.972919e+00   \n",
       "min    -4.253000e-02  2.685500e-01 -2.146700e+00  1.203892e+01  7.000000e+01   \n",
       "25%    -1.090000e-03  1.500092e+01 -9.020000e-02  1.253358e+01  7.000000e+01   \n",
       "50%    -7.000000e-05  9.403381e+01  4.304000e-01  1.266931e+01  7.000000e+01   \n",
       "75%     1.010000e-03  1.005112e+02  8.929000e-01  1.275681e+01  8.000000e+01   \n",
       "max     4.051000e-02  1.008774e+02  3.148700e+00  1.281139e+01  8.000000e+01   \n",
       "\n",
       "              C09  ...           C77           C78           C79  \\\n",
       "count   1004402.0  ...  1.004402e+06  1.004402e+06  1.004402e+06   \n",
       "unique        NaN  ...           NaN           NaN           NaN   \n",
       "top           NaN  ...           NaN           NaN           NaN   \n",
       "freq          NaN  ...           NaN           NaN           NaN   \n",
       "mean          1.0  ...  1.105578e+00  3.386906e+01  4.192900e+00   \n",
       "std           0.0  ...  8.886521e-02  2.897106e+00  3.445795e+00   \n",
       "min           1.0  ...  5.532800e-01  2.815872e+01  0.000000e+00   \n",
       "25%           1.0  ...  1.053010e+00  3.083306e+01  0.000000e+00   \n",
       "50%           1.0  ...  1.111760e+00  3.548735e+01  5.327940e+00   \n",
       "75%           1.0  ...  1.165160e+00  3.602524e+01  6.862630e+00   \n",
       "max           1.0  ...  2.088320e+00  3.805496e+01  1.000000e+01   \n",
       "\n",
       "                 C80           C81        C82           C83           C84  \\\n",
       "count   1.004402e+06  1.004402e+06  1004402.0  1.004402e+06  1.004402e+06   \n",
       "unique           NaN           NaN        NaN           NaN           NaN   \n",
       "top              NaN           NaN        NaN           NaN           NaN   \n",
       "freq             NaN           NaN        NaN           NaN           NaN   \n",
       "mean    2.202201e+03  3.662623e+02        1.0  1.009977e+03  1.200010e+01   \n",
       "std     1.329775e+03  6.061224e+01        0.0  3.981555e+01  1.718555e-02   \n",
       "min     1.112275e+01  2.309570e+02        1.0  8.900452e+02  1.200000e+01   \n",
       "25%     5.533513e+02  3.180339e+02        1.0  9.775195e+02  1.200000e+01   \n",
       "50%     3.176862e+03  3.652344e+02        1.0  1.007838e+03  1.200000e+01   \n",
       "75%     3.184745e+03  4.146954e+02        1.0  1.030605e+03  1.200000e+01   \n",
       "max     3.190000e+03  4.997649e+02        1.0  1.121855e+03  1.714934e+01   \n",
       "\n",
       "              C85           C86  \n",
       "count   1004402.0  1.004402e+06  \n",
       "unique        NaN           NaN  \n",
       "top           NaN           NaN  \n",
       "freq          NaN           NaN  \n",
       "mean         50.0  1.126177e+03  \n",
       "std           0.0  1.693609e+03  \n",
       "min          50.0 -1.120000e+02  \n",
       "25%          50.0  7.000000e+00  \n",
       "50%          50.0  1.060000e+02  \n",
       "75%          50.0  2.376000e+03  \n",
       "max          50.0  1.299300e+04  \n",
       "\n",
       "[11 rows x 87 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF_RAW.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터셋은 공격을 받지 않은 평상시 데이터이고 시간을 나타내는 필드인 timestamp가 있으며, 나머지 필드는 모두 비식별화된 센서/액추에이터의 값입니다.\n",
    "정규화는 센서/액추에이터 필드만을 대상으로 해야 합니다.\n",
    "\n",
    "본 문서에서는 전체 데이터를 대상으로 이상을 탐지하므로 \"attack\" 필드만 사용하였습니다.\n",
    "\n",
    "VALID_COLUMNS_IN_TRAIN_DATASET은 학습 데이터셋에 있는 모든 센서/액추에이터 필드를 담고 있습니다.\n",
    "가끔 학습 데이터셋에 존재하지 않는 필드가 테스트 데이터셋에 존재하는 경우가 있습니다.\n",
    "학습 시 보지 못했던 필드에 대해서 테스트를 할 수 없으므로 학습 데이터셋을 기준으로 필드 이름을 얻어냈습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C01', 'C04', 'C05', 'C06', 'C07', 'C11', 'C12', 'C13', 'C14', 'C15',\n",
       "       'C16', 'C20', 'C21', 'C23', 'C24', 'C25', 'C27', 'C28', 'C30', 'C31',\n",
       "       'C32', 'C33', 'C35', 'C37', 'C40', 'C41', 'C43', 'C44', 'C45', 'C46',\n",
       "       'C47', 'C50', 'C51', 'C53', 'C56', 'C57', 'C58', 'C59', 'C60', 'C62',\n",
       "       'C65', 'C66', 'C67', 'C68', 'C70', 'C71', 'C72', 'C73', 'C74', 'C75',\n",
       "       'C76', 'C77', 'C78', 'C79', 'C80', 'C81', 'C83', 'C86'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIMESTAMP_FIELD = \"timestamp\"\n",
    "IDSTAMP_FIELD = 'id'\n",
    "ATTACK_FIELD = \"attack\"\n",
    "VALID_COLUMNS_IN_TRAIN_DATASET = TRAIN_DF_RAW.columns.drop([TIMESTAMP_FIELD, 'C02', 'C03', 'C08'  ,'C09', 'C10', 'C17', 'C18', 'C19', 'C22', 'C26', 'C29', 'C34', 'C36', 'C38', 'C39', 'C42', 'C48', 'C49', 'C52', 'C54', 'C55', 'C61', 'C63', 'C64', 'C69', 'C82', 'C84', 'C85'])\n",
    "VALID_COLUMNS_IN_TRAIN_DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAG_MIN과 TAG_MAX는 학습 데이터셋에서 최솟값 최댓값을 얻은 결과입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_MIN = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].min()\n",
    "TAG_MAX = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].max()\n",
    "TAG_MEAN = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].mean()\n",
    "TAG_STD = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize 함수는 Dataframe을 정규화합니다.\n",
    "정규화 방법은 최솟값, 최댓값을 이용하여 0~1의 범위에 들어오도록 하는 것입니다.\n",
    "\n",
    "가끔 값이 전혀 변하지 않는 필드가 있습니다.\n",
    "이 경우 최솟값과 최댓값이 같을 것입니다.\n",
    "본 문서에서는 이런 필드를 모두 0으로 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    ndf = df.copy()\n",
    "    for c in df.columns:\n",
    "        if TAG_MIN[c] == TAG_MAX[c]:\n",
    "            ndf[c] = df[c] - TAG_MIN[c]\n",
    "        else:\n",
    "            ndf[c] = (df[c] - TAG_MIN[c]) / (TAG_MAX[c] - TAG_MIN[c])\n",
    "    return ndf\n",
    "\n",
    "def zscore(df):\n",
    "    ndf = df.copy()\n",
    "    for c in df.columns:\n",
    "        if TAG_STD[c] == 0:\n",
    "            ndf[c] = df[c] - TAG_MEAN[c]\n",
    "        else:\n",
    "            ndf[c] = (df[c] - TAG_MEAN[c]) / TAG_STD[c]\n",
    "    return ndf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN_DF는 정규화를 마친 후 exponential weighted function을 통과시킨 결과입니다.\n",
    "센서에서 발생하는 noise를 smoothing 시켜주기를 기대하고 적용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C01</th>\n",
       "      <th>C04</th>\n",
       "      <th>C05</th>\n",
       "      <th>C06</th>\n",
       "      <th>C07</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>...</th>\n",
       "      <th>C74</th>\n",
       "      <th>C75</th>\n",
       "      <th>C76</th>\n",
       "      <th>C77</th>\n",
       "      <th>C78</th>\n",
       "      <th>C79</th>\n",
       "      <th>C80</th>\n",
       "      <th>C81</th>\n",
       "      <th>C83</th>\n",
       "      <th>C86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.195926</td>\n",
       "      <td>-0.510446</td>\n",
       "      <td>-1.286610</td>\n",
       "      <td>-0.232211</td>\n",
       "      <td>0.300756</td>\n",
       "      <td>-0.705245</td>\n",
       "      <td>0.788264</td>\n",
       "      <td>0.339643</td>\n",
       "      <td>-0.387054</td>\n",
       "      <td>-1.314503</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.316890</td>\n",
       "      <td>-1.797287</td>\n",
       "      <td>-0.398040</td>\n",
       "      <td>-2.059612</td>\n",
       "      <td>-1.307732</td>\n",
       "      <td>0.840236</td>\n",
       "      <td>-1.208580</td>\n",
       "      <td>-1.482520</td>\n",
       "      <td>0.120975</td>\n",
       "      <td>1.405178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.403835</td>\n",
       "      <td>0.291271</td>\n",
       "      <td>-1.274333</td>\n",
       "      <td>-0.516235</td>\n",
       "      <td>0.300756</td>\n",
       "      <td>-0.674580</td>\n",
       "      <td>0.790907</td>\n",
       "      <td>-0.659897</td>\n",
       "      <td>-0.378450</td>\n",
       "      <td>-1.314503</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.348800</td>\n",
       "      <td>-1.797287</td>\n",
       "      <td>-0.383606</td>\n",
       "      <td>-2.059612</td>\n",
       "      <td>-1.306536</td>\n",
       "      <td>0.840236</td>\n",
       "      <td>-1.252031</td>\n",
       "      <td>-1.485776</td>\n",
       "      <td>0.120975</td>\n",
       "      <td>1.398200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.742052</td>\n",
       "      <td>-0.348808</td>\n",
       "      <td>-1.231228</td>\n",
       "      <td>-0.469486</td>\n",
       "      <td>0.300756</td>\n",
       "      <td>-0.649292</td>\n",
       "      <td>0.791146</td>\n",
       "      <td>-0.108109</td>\n",
       "      <td>-0.386201</td>\n",
       "      <td>-1.314503</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.366476</td>\n",
       "      <td>-1.795847</td>\n",
       "      <td>-0.399972</td>\n",
       "      <td>-2.098338</td>\n",
       "      <td>-1.304174</td>\n",
       "      <td>0.840236</td>\n",
       "      <td>-1.310443</td>\n",
       "      <td>-1.431503</td>\n",
       "      <td>0.120975</td>\n",
       "      <td>1.395975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.123514</td>\n",
       "      <td>0.534879</td>\n",
       "      <td>-1.195489</td>\n",
       "      <td>-0.294992</td>\n",
       "      <td>0.300756</td>\n",
       "      <td>-0.625981</td>\n",
       "      <td>0.791169</td>\n",
       "      <td>-0.041992</td>\n",
       "      <td>-0.378450</td>\n",
       "      <td>-1.314503</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.358815</td>\n",
       "      <td>-1.797143</td>\n",
       "      <td>-0.380681</td>\n",
       "      <td>-2.125367</td>\n",
       "      <td>-1.300028</td>\n",
       "      <td>0.840236</td>\n",
       "      <td>-1.347819</td>\n",
       "      <td>-1.401692</td>\n",
       "      <td>0.120975</td>\n",
       "      <td>1.414356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.769093</td>\n",
       "      <td>0.305677</td>\n",
       "      <td>-1.188090</td>\n",
       "      <td>-0.277560</td>\n",
       "      <td>0.300756</td>\n",
       "      <td>-0.596266</td>\n",
       "      <td>0.791171</td>\n",
       "      <td>-0.035386</td>\n",
       "      <td>-0.377676</td>\n",
       "      <td>-1.314503</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.337214</td>\n",
       "      <td>-1.797272</td>\n",
       "      <td>-0.359600</td>\n",
       "      <td>-2.112572</td>\n",
       "      <td>-1.299850</td>\n",
       "      <td>0.840236</td>\n",
       "      <td>-1.366340</td>\n",
       "      <td>-1.401130</td>\n",
       "      <td>0.120975</td>\n",
       "      <td>1.404501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259195</th>\n",
       "      <td>0.088121</td>\n",
       "      <td>0.199914</td>\n",
       "      <td>0.853775</td>\n",
       "      <td>0.169812</td>\n",
       "      <td>-0.286211</td>\n",
       "      <td>-1.452286</td>\n",
       "      <td>-0.793319</td>\n",
       "      <td>-0.183159</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>-0.563108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732029</td>\n",
       "      <td>0.789496</td>\n",
       "      <td>-0.679931</td>\n",
       "      <td>0.762588</td>\n",
       "      <td>0.409312</td>\n",
       "      <td>1.685271</td>\n",
       "      <td>0.733961</td>\n",
       "      <td>0.064095</td>\n",
       "      <td>-0.600706</td>\n",
       "      <td>-0.586255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259196</th>\n",
       "      <td>-0.118703</td>\n",
       "      <td>-0.121930</td>\n",
       "      <td>0.853775</td>\n",
       "      <td>0.116677</td>\n",
       "      <td>-0.286211</td>\n",
       "      <td>-1.456110</td>\n",
       "      <td>-0.793272</td>\n",
       "      <td>-0.028449</td>\n",
       "      <td>-0.083014</td>\n",
       "      <td>-0.563108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732091</td>\n",
       "      <td>0.789496</td>\n",
       "      <td>-0.687148</td>\n",
       "      <td>0.718377</td>\n",
       "      <td>0.403100</td>\n",
       "      <td>1.685271</td>\n",
       "      <td>0.732037</td>\n",
       "      <td>0.067946</td>\n",
       "      <td>-0.600706</td>\n",
       "      <td>-0.609791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259197</th>\n",
       "      <td>-0.249835</td>\n",
       "      <td>0.836642</td>\n",
       "      <td>0.853775</td>\n",
       "      <td>0.103398</td>\n",
       "      <td>-0.286211</td>\n",
       "      <td>-1.458827</td>\n",
       "      <td>-0.793267</td>\n",
       "      <td>-0.344103</td>\n",
       "      <td>-0.050011</td>\n",
       "      <td>-0.563108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732690</td>\n",
       "      <td>0.789496</td>\n",
       "      <td>-0.700474</td>\n",
       "      <td>0.721653</td>\n",
       "      <td>0.400465</td>\n",
       "      <td>1.685271</td>\n",
       "      <td>0.732099</td>\n",
       "      <td>0.034496</td>\n",
       "      <td>-0.600706</td>\n",
       "      <td>-0.611614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259198</th>\n",
       "      <td>-0.238043</td>\n",
       "      <td>0.417962</td>\n",
       "      <td>0.853443</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>-0.286211</td>\n",
       "      <td>-1.458462</td>\n",
       "      <td>-0.793267</td>\n",
       "      <td>0.116234</td>\n",
       "      <td>-0.012640</td>\n",
       "      <td>-0.563108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729786</td>\n",
       "      <td>0.789496</td>\n",
       "      <td>-0.731674</td>\n",
       "      <td>0.721980</td>\n",
       "      <td>0.398897</td>\n",
       "      <td>1.685271</td>\n",
       "      <td>0.732698</td>\n",
       "      <td>0.029541</td>\n",
       "      <td>-0.600706</td>\n",
       "      <td>-0.620298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259199</th>\n",
       "      <td>-0.143199</td>\n",
       "      <td>-0.018019</td>\n",
       "      <td>0.853576</td>\n",
       "      <td>0.279097</td>\n",
       "      <td>-0.286211</td>\n",
       "      <td>-1.458638</td>\n",
       "      <td>-0.793267</td>\n",
       "      <td>0.491478</td>\n",
       "      <td>-0.034456</td>\n",
       "      <td>-0.563108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.789496</td>\n",
       "      <td>-0.716593</td>\n",
       "      <td>0.776095</td>\n",
       "      <td>0.396488</td>\n",
       "      <td>1.685271</td>\n",
       "      <td>0.729794</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>-0.600706</td>\n",
       "      <td>-0.606819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004402 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             C01       C04       C05       C06       C07       C11       C12  \\\n",
       "0      -0.195926 -0.510446 -1.286610 -0.232211  0.300756 -0.705245  0.788264   \n",
       "1      -0.403835  0.291271 -1.274333 -0.516235  0.300756 -0.674580  0.790907   \n",
       "2      -0.742052 -0.348808 -1.231228 -0.469486  0.300756 -0.649292  0.791146   \n",
       "3      -0.123514  0.534879 -1.195489 -0.294992  0.300756 -0.625981  0.791169   \n",
       "4      -0.769093  0.305677 -1.188090 -0.277560  0.300756 -0.596266  0.791171   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "259195  0.088121  0.199914  0.853775  0.169812 -0.286211 -1.452286 -0.793319   \n",
       "259196 -0.118703 -0.121930  0.853775  0.116677 -0.286211 -1.456110 -0.793272   \n",
       "259197 -0.249835  0.836642  0.853775  0.103398 -0.286211 -1.458827 -0.793267   \n",
       "259198 -0.238043  0.417962  0.853443  0.181825 -0.286211 -1.458462 -0.793267   \n",
       "259199 -0.143199 -0.018019  0.853576  0.279097 -0.286211 -1.458638 -0.793267   \n",
       "\n",
       "             C13       C14       C15  ...       C74       C75       C76  \\\n",
       "0       0.339643 -0.387054 -1.314503  ... -1.316890 -1.797287 -0.398040   \n",
       "1      -0.659897 -0.378450 -1.314503  ... -1.348800 -1.797287 -0.383606   \n",
       "2      -0.108109 -0.386201 -1.314503  ... -1.366476 -1.795847 -0.399972   \n",
       "3      -0.041992 -0.378450 -1.314503  ... -1.358815 -1.797143 -0.380681   \n",
       "4      -0.035386 -0.377676 -1.314503  ... -1.337214 -1.797272 -0.359600   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "259195 -0.183159  0.012841 -0.563108  ...  0.732029  0.789496 -0.679931   \n",
       "259196 -0.028449 -0.083014 -0.563108  ...  0.732091  0.789496 -0.687148   \n",
       "259197 -0.344103 -0.050011 -0.563108  ...  0.732690  0.789496 -0.700474   \n",
       "259198  0.116234 -0.012640 -0.563108  ...  0.729786  0.789496 -0.731674   \n",
       "259199  0.491478 -0.034456 -0.563108  ...  0.726531  0.789496 -0.716593   \n",
       "\n",
       "             C77       C78       C79       C80       C81       C83       C86  \n",
       "0      -2.059612 -1.307732  0.840236 -1.208580 -1.482520  0.120975  1.405178  \n",
       "1      -2.059612 -1.306536  0.840236 -1.252031 -1.485776  0.120975  1.398200  \n",
       "2      -2.098338 -1.304174  0.840236 -1.310443 -1.431503  0.120975  1.395975  \n",
       "3      -2.125367 -1.300028  0.840236 -1.347819 -1.401692  0.120975  1.414356  \n",
       "4      -2.112572 -1.299850  0.840236 -1.366340 -1.401130  0.120975  1.404501  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "259195  0.762588  0.409312  1.685271  0.733961  0.064095 -0.600706 -0.586255  \n",
       "259196  0.718377  0.403100  1.685271  0.732037  0.067946 -0.600706 -0.609791  \n",
       "259197  0.721653  0.400465  1.685271  0.732099  0.034496 -0.600706 -0.611614  \n",
       "259198  0.721980  0.398897  1.685271  0.732698  0.029541 -0.600706 -0.620298  \n",
       "259199  0.776095  0.396488  1.685271  0.729794  0.025553 -0.600706 -0.606819  \n",
       "\n",
       "[1004402 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     norm_args = train_raw[valid_cols].mean(), train_raw[valid_cols].std()\n",
    "\n",
    "# TRAIN_DF = normalize(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.9).mean()\n",
    "TRAIN_DF = zscore(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.9).mean()\n",
    "\n",
    "TRAIN_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "boundary_check 함수는 Pandas Dataframe에 있는 값 중 1 초과의 값이 있는지, 0 미만의 값이 있는지, NaN이 있는지 점검합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_check(df):\n",
    "    x = np.array(df, dtype=np.float32)\n",
    "    return np.any(x > 1.0), np.any(x < 0), np.any(np.isnan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_check(TRAIN_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1보다 큰 값, 0보다 작은 값, not a number가 없습니다. 정규화가 정상적으로 처리되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 모델 설정 & 데이터 입출력 정의\n",
    "\n",
    "딥러닝 학습과 추론에는 PyTorch를 사용했습니다.\n",
    "\n",
    "베이스라인 모델은 Stacked RNN(GRU cells)을 이용해서 이상을 탐지합니다.\n",
    "정상 데이터만 학습해야 하고, 정상 데이터에는 어떠한 label도 없으므로 unsupervised learning을 해야 합니다.\n",
    "\n",
    "본 모델에서는 슬라이딩 윈도우를 통해 시계열 데이터의 일부를 가져와서 해당 윈도우의 패턴을 기억하도록 했습니다.\n",
    "슬라이딩 윈도우는 90초(HAI는 1초마다 샘플링되어 있습니다)로 설정했습니다.\n",
    "\n",
    "모델의 입출력은 다음과 같이 설정했습니다.\n",
    "- 입력 : 윈도우의 앞부분 89초에 해당하는 값\n",
    "- 출력 : 윈도우의 가장 마지막 초(90번째 초)의 값\n",
    "\n",
    "이후 탐지 시에는 모델이 출력하는 값(예측값)과 실제로 들어온 값의 차를 보고 차이가 크면 이상으로 간주했습니다.\n",
    "많은 오차가 발생한다는 것은 기존에 학습 데이터셋에서 본 적이 없는 패턴이기 때문이라는 가정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_GIVEN = 159\n",
    "WINDOW_SIZE = 160\n",
    "\n",
    "\n",
    "class HaiDataset(Dataset):\n",
    "    def __init__(self, timestamps, df, stride=1, attacks=None):\n",
    "        self.ts = np.array(timestamps)\n",
    "        self.tag_values = np.array(df, dtype=np.float32)\n",
    "        self.valid_idxs = []\n",
    "        for L in trange(len(self.ts) - WINDOW_SIZE + 1):\n",
    "            R = L + WINDOW_SIZE - 1\n",
    "            if dateutil.parser.parse(self.ts[R]) - dateutil.parser.parse(\n",
    "                self.ts[L]\n",
    "            ) == timedelta(seconds=WINDOW_SIZE - 1):\n",
    "                self.valid_idxs.append(L)\n",
    "        self.valid_idxs = np.array(self.valid_idxs, dtype=np.int32)[::stride]\n",
    "        self.n_idxs = len(self.valid_idxs)\n",
    "        print(f\"# of valid windows: {self.n_idxs}\")\n",
    "        if attacks is not None:\n",
    "            self.attacks = np.array(attacks, dtype=np.float32)\n",
    "            self.with_attack = True\n",
    "        else:\n",
    "            self.with_attack = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_idxs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.valid_idxs[idx]\n",
    "        last = i + WINDOW_SIZE - 1\n",
    "        item = {\"attack\": self.attacks[last]} if self.with_attack else {}\n",
    "        item[\"ts\"] = self.ts[i + WINDOW_SIZE - 1]\n",
    "        item[\"given\"] = torch.from_numpy(self.tag_values[i : i + WINDOW_GIVEN])\n",
    "        item[\"answer\"] = torch.from_numpy(self.tag_values[last])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HaiDataset 클래스는 PyTorch의 Dataset 인터페이스를 정의한 것입니다.\n",
    "\n",
    "데이터셋을 읽을 때는 슬라이딩 윈도우가 유효한 지 점검합니다.\n",
    "정상적인 윈도우라면 원도우의 첫 시각과 마지막 시각의 차가 89초가 되어야 합니다.\n",
    "\n",
    "stride 파라미터는 슬라이딩을 할 때 크기를 의미합니다.\n",
    "전체 윈도우를 모두 학습할 수도 있지만, 시계열 데이터에서는 슬라이딩 윈도우를 1초씩 적용하면 이전 윈도우와 다음 윈도우의 값이 거의 같습니다.\n",
    "본 노트북에서는 학습을 빠르게 마치기 위해 10초씩 건너뛰면서 데이터를 추출하도록 했습니다.\n",
    "(물론 슬라이딩 크기를 1로 설정하여 모든 데이터셋을 보게 하면 더 좋을 것입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c0ff3b3a0646ab8979eec1bdbbffd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1004103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# of valid windows: 200522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ts': '2021-07-11 10:04:59',\n",
       " 'given': tensor([[-0.1959, -0.5104, -1.2866,  ..., -1.4825,  0.1210,  1.4052],\n",
       "         [-0.4038,  0.2913, -1.2743,  ..., -1.4858,  0.1210,  1.3982],\n",
       "         [-0.7421, -0.3488, -1.2312,  ..., -1.4315,  0.1210,  1.3960],\n",
       "         ...,\n",
       "         [-0.6436,  1.0604, -1.1908,  ...,  0.0497,  0.1210,  2.1756],\n",
       "         [-0.0780,  1.1902, -1.1850,  ...,  0.1645,  0.1210,  2.1608],\n",
       "         [-0.7485,  0.8474, -1.1842,  ...,  0.1760,  0.1210,  1.8963]]),\n",
       " 'answer': tensor([-0.3645,  0.7365, -1.1841, -0.2348,  0.3008,  0.8820,  0.4743, -0.0114,\n",
       "         -0.8843, -1.3409, -1.1071, -0.5315, -0.8770,  0.3578,  0.6963, -0.0845,\n",
       "          0.3952,  0.0247,  0.7886,  0.0662, -0.2994, -0.4397,  1.6001, -1.0989,\n",
       "         -1.3557, -1.0005,  0.6873, -0.3549, -0.2294,  0.9009,  0.3855,  0.8870,\n",
       "          0.9326, -0.7293,  0.5871,  0.9246, -0.4097, -0.2656, -0.2486,  0.8819,\n",
       "         -0.6718, -0.8210, -1.2862, -1.0620, -0.3029, -0.8828, -1.2096, -0.0572,\n",
       "         -1.3036, -1.2269, -0.3612, -1.0295, -1.0510,  0.8402, -1.3496,  0.2405,\n",
       "          0.1210,  1.6403])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAI_DATASET_TRAIN = HaiDataset(TRAIN_DF_RAW[TIMESTAMP_FIELD], TRAIN_DF, stride=5)\n",
    "HAI_DATASET_TRAIN[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋이 잘 로드되는 것을 볼 수 있습니다.\n",
    "\n",
    "모델은 3층 bidirectional GRU를 사용합니다.\n",
    "Hidden cell의 크기는 100으로 설정했습니다.\n",
    "Dropout은 사용하지 않았습니다.\n",
    "\n",
    "모델이 윈도우의 가장 첫 번째 값과 RNN의 출력을 더해서 내보내도록 skip connection(forward 메소드의 return 문 참조)을 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDDENS = 100\n",
    "N_LAYERS = 3\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "class StackedGRU(torch.nn.Module):\n",
    "    def __init__(self, n_tags):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size=n_tags,\n",
    "            hidden_size=N_HIDDENS,\n",
    "            num_layers=N_LAYERS,\n",
    "            bidirectional=True,\n",
    "            dropout=0,\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(N_HIDDENS * 2, n_tags)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(0, 1)  # (batch, seq, params) -> (seq, batch, params)\n",
    "        self.rnn.flatten_parameters()\n",
    "        outs, _ = self.rnn(x)\n",
    "        out = self.fc(outs[-1])\n",
    "        return x[0] + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedGRU(\n",
       "  (rnn): GRU(58, 100, num_layers=3, bidirectional=True)\n",
       "  (fc): Linear(in_features=200, out_features=58, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = StackedGRU(n_tags=TRAIN_DF.shape[1])\n",
    "MODEL.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신규 모델 학습\n",
    "\n",
    "모델 학습을 직접 하려면 아래 코드를 실행하시면 됩니다.\n",
    "\n",
    "이미 학습된 모델을 로드해서 결과만 보시려면 아래 '모델 불러오기' section으로 가셔서 실행을 이어가시면 됩니다.\n",
    "\n",
    "Loss function은 MSE를 선택했고, optimizer는 AdamW(Loshchilov & Hutter, \"Decoupled Weight Decay Regularization\", ICLR 2019)를 사용합니다.\n",
    "\n",
    "학습 시 epoch loss가 가장 좋았던 모델의 파라미터를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, batch_size, n_epochs):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    epochs = trange(n_epochs, desc=\"training\")\n",
    "    best = {\"loss\": sys.float_info.max}\n",
    "    loss_history = []\n",
    "    for e in epochs:\n",
    "        epoch_loss = 0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            given = batch[\"given\"].cuda()\n",
    "            guess = model(given)\n",
    "            answer = batch[\"answer\"].cuda()\n",
    "            loss = loss_fn(answer, guess)\n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        loss_history.append(epoch_loss)\n",
    "        epochs.set_postfix_str(f\"loss: {epoch_loss:.6f}\")\n",
    "        if epoch_loss < best[\"loss\"]:\n",
    "            best[\"state\"] = model.state_dict()\n",
    "            best[\"loss\"] = epoch_loss\n",
    "            best[\"epoch\"] = e + 1\n",
    "    return best, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 32 에포크 진행했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ad8423ccb3496e956753eb90a2ae3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training', style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 9.12 GiB (GPU 0; 10.76 GiB total capacity; 2.59 GiB already allocated; 7.04 GiB free; 2.60 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-880e8985b588>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, model, batch_size, n_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mgiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"given\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiven\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0482a25521d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch, seq, params) -> (seq, batch, params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    838\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    839\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 9.12 GiB (GPU 0; 10.76 GiB total capacity; 2.59 GiB already allocated; 7.04 GiB free; 2.60 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MODEL.train()\n",
    "BEST_MODEL, LOSS_HISTORY = train(HAI_DATASET_TRAIN, MODEL, BATCH_SIZE, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BEST_MODEL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-882342ea3918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBEST_MODEL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBEST_MODEL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'BEST_MODEL' is not defined"
     ]
    }
   ],
   "source": [
    "BEST_MODEL[\"loss\"], BEST_MODEL[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pt\", \"wb\") as f:\n",
    "    torch.save(\n",
    "        {\n",
    "            \"state\": BEST_MODEL[\"state\"],\n",
    "            \"best_epoch\": BEST_MODEL[\"epoch\"],\n",
    "            \"loss_history\": LOSS_HISTORY,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기\n",
    "\n",
    "이미 학습된 모델 파라미터와 training loss 기록을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pt\", \"rb\") as f:\n",
    "    SAVED_MODEL = torch.load(f)\n",
    "\n",
    "MODEL.load_state_dict(SAVED_MODEL[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(\"Training Loss Graph\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(SAVED_MODEL[\"loss_history\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델을 이용한 탐지\n",
    "\n",
    "검증 데이터셋을 불러와서 모델에 입력으로 주고 예측값과 실제값의 차를 얻어봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋에 대해서도 만들어둔 함수를 이용해서 점검해봅니다.\n",
    "Not a number가 있는지 점검하는 것이 주요 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DF_RAW = dataframe_from_csvs(VALIDATION_DATASET)\n",
    "VALIDATION_DF_RAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋도 정상 데이터셋의 최솟값, 최댓값을 이용해서 정규화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DF = normalize(VALIDATION_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_check(VALIDATION_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격 데이터셋에서는 확실히 정상 데이터의 최솟값과 최댓값을 벗어나는 값이 나타나고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAI_DATASET_VALIDATION = HaiDataset(\n",
    "    VALIDATION_DF_RAW[TIMESTAMP_FIELD], VALIDATION_DF, attacks=VALIDATION_DF_RAW[ATTACK_FIELD]\n",
    ")\n",
    "HAI_DATASET_VALIDATION[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋에 대해서도 PyTorch Dataset 인스턴스를 만들었습니다.\n",
    "모든 데이터 포인트에 대해 점검해야 하므로 학습 데이터 때와는 다르게 슬라이딩의 크기는 1로 두어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dataset, model, batch_size):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    ts, dist, att = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            given = batch[\"given\"].cuda()\n",
    "            answer = batch[\"answer\"].cuda()\n",
    "            guess = model(given)\n",
    "            ts.append(np.array(batch[\"ts\"]))\n",
    "            dist.append(torch.abs(answer - guess).cpu().numpy())\n",
    "            try:\n",
    "                att.append(np.array(batch[\"attack\"]))\n",
    "            except:\n",
    "                att.append(np.zeros(batch_size))\n",
    "            \n",
    "    return (\n",
    "        np.concatenate(ts),\n",
    "        np.concatenate(dist),\n",
    "        np.concatenate(att),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference 함수는 데이터를 순차적으로 보면서 모델이 예측한 값과 실제 값의 차를 구해서 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MODEL.eval()\n",
    "CHECK_TS, CHECK_DIST, CHECK_ATT = inference(HAI_DATASET_VALIDATION, MODEL, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK_DIST는 검증 데이터셋 전체 시간대에 대해 모든 필드의 |예측값 - 실제값|을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_DIST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격 여부 판단을 위해 같은 시각에서 전체 필드가 산출하는 차의 평균을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 눈으로 확인하기 위해 그래프를 그려보겠습니다.\n",
    "piece 파라미터는 그래프를 몇 개로 나누어 그릴지를 결정합니다.\n",
    "세세한 결과를 보고 싶을 경우 숫자를 늘리면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_graph(xs, att, piece=2, THRESHOLD=None):\n",
    "    l = xs.shape[0]\n",
    "    chunk = l // piece\n",
    "    fig, axs = plt.subplots(piece, figsize=(20, 4 * piece))\n",
    "    for i in range(piece):\n",
    "        L = i * chunk\n",
    "        R = min(L + chunk, l)\n",
    "        xticks = range(L, R)\n",
    "        axs[i].plot(xticks, xs[L:R])\n",
    "        if len(xs[L:R]) > 0:\n",
    "            peak = max(xs[L:R])\n",
    "            axs[i].plot(xticks, att[L:R] * peak * 0.3)\n",
    "        if THRESHOLD!=None:\n",
    "            axs[i].axhline(y=THRESHOLD, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.026\n",
    "check_graph(ANOMALY_SCORE, CHECK_ATT, piece=2, THRESHOLD=THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주황색 선은 공격 위치를 나타내고, 파란색 선은 (평균) 오차의 크기를 나타냅니다.\n",
    "전반적으로 공격 위치에서 큰 오차를 보이고 있습니다.\n",
    "\n",
    "임의의 threshold(빨간색 선)가 넘어갈 경우 공격으로 간주합니다.\n",
    "공격은 1로 정상은 0으로 표기합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_labels(distance, threshold):\n",
    "    xs = np.zeros_like(distance)\n",
    "    xs[distance > threshold] = 1\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프를 보면 대략 0.022를 기준으로 설정할 수 있을 것으로 보입니다.\n",
    "여러 번의 실험을 통해 정밀하게 임계치를 선택하면 더 좋은 결과를 얻을 수 있을 것으로 예상합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = put_labels(ANOMALY_SCORE, THRESHOLD)\n",
    "LABELS, LABELS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답지(ATTACK_LABELS)도 동일하게 추출합니다.\n",
    "검증 데이터셋에 공격 여부를 나타내는 필드에는 정상을 0으로 공격을 1로 표기하고 있습니다.\n",
    "위에 정의한 put_labels 함수를 이용해서 0.5를 기준으로 같은 방식으로 TaPR을 위한 label을 붙여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_LABELS = put_labels(np.array(VALIDATION_DF_RAW[ATTACK_FIELD]), threshold=0.5)\n",
    "ATTACK_LABELS, ATTACK_LABELS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "탐지 모델이 윈도우 방식으로 판단을 진행했기 때문에,\n",
    "1. 첫 시작의 몇 초는 판단을 내릴 수 없고\n",
    "2. 데이터셋 중간에 시간이 연속되지 않는 구간에 대해서는 판단을 내릴 수 없습니다.\n",
    "\n",
    "위에서 보시는 바와 같이 정답에 비해 얻어낸 label의 수가 적습니다.\n",
    "\n",
    "아래의 fill_blank 함수는 빈칸을 채워줍니다.\n",
    "빈 곳은 정상(0) 표기하고 나머지는 모델의 판단(정상 0, 비정상 1)을 채워줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_blank(check_ts, labels, total_ts):\n",
    "    def ts_generator():\n",
    "        for t in total_ts:\n",
    "            yield dateutil.parser.parse(t)\n",
    "\n",
    "    def label_generator():\n",
    "        for t, label in zip(check_ts, labels):\n",
    "            yield dateutil.parser.parse(t), label\n",
    "\n",
    "    g_ts = ts_generator()\n",
    "    g_label = label_generator()\n",
    "    final_labels = []\n",
    "\n",
    "    try:\n",
    "        current = next(g_ts)\n",
    "        ts_label, label = next(g_label)\n",
    "        while True:\n",
    "            if current > ts_label:\n",
    "                ts_label, label = next(g_label)\n",
    "                continue\n",
    "            elif current < ts_label:\n",
    "                final_labels.append(0)\n",
    "                current = next(g_ts)\n",
    "                continue\n",
    "            final_labels.append(label)\n",
    "            current = next(g_ts)\n",
    "            ts_label, label = next(g_label)\n",
    "    except StopIteration:\n",
    "        return np.array(final_labels, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FINAL_LABELS = fill_blank(CHECK_TS, LABELS, np.array(VALIDATION_DF_RAW[TIMESTAMP_FIELD]))\n",
    "FINAL_LABELS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가\n",
    "\n",
    "평가는 TaPR을 사용합니다.\n",
    "정답(ATTACK_LABELS)과 모델의 결과(FINAL_LABELS)의 길이가 같은지 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaPR 점수를 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaPR = etapr.evaluate(anomalies=ATTACK_LABELS, predictions=FINAL_LABELS)\n",
    "print(f\"F1: {TaPR['f1']:.3f} (TaP: {TaPR['TaP']:.3f}, TaR: {TaPR['TaR']:.3f})\")\n",
    "print(f\"# of detected anomalies: {len(TaPR['Detected_Anomalies'])}\")\n",
    "print(f\"Detected anomalies: {TaPR['Detected_Anomalies']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터셋 예측\n",
    "학습 데이터셋과 검증 데이터셋을 이용해 만든 모델로 테스트 데이터셋 결과를 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF_RAW = dataframe_from_csvs(TEST_DATASET)\n",
    "TEST_DF_RAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터셋도 정상 데이터셋의 최솟값, 최댓값을 이용해서 정규화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF = normalize(TEST_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.9).mean()\n",
    "TEST_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터셋에 대해서도 만들어둔 함수를 이용해서 점검해봅니다.\n",
    "Not a number가 있는지 점검하는 것이 주요 목적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_check(TEST_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAI_DATASET_TEST = HaiDataset(\n",
    "    TEST_DF_RAW[TIMESTAMP_FIELD], TEST_DF, attacks=None\n",
    ")\n",
    "HAI_DATASET_VALIDATION[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터셋에 대해서도 PyTorch Dataset 인스턴스를 만들었습니다. 모든 데이터 포인트에 대해 점검해야 하므로 검증 데이터 때와 마찬가지로 슬라이딩의 크기는 1로 두어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference 함수로 데이터를 순차적으로 보면서 모델이 예측한 값과 실제 값의 차를 구해서 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MODEL.eval()\n",
    "CHECK_TS, CHECK_DIST, CHECK_ATT = inference(HAI_DATASET_TEST, MODEL, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공격 여부 판단을 위해 같은 시각에서 전체 필드가 산출하는 차의 평균을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 눈으로 확인하기 위해 그래프를 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_graph(ANOMALY_SCORE, CHECK_ATT, piece=3, THRESHOLD=THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋을 이용해 찾은 threshold를 이용해 공격 여부를 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = put_labels(ANOMALY_SCORE, THRESHOLD)\n",
    "LABELS, LABELS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측한 결과를 제출양식에 맞춰 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('dataset/sample_submission.csv')\n",
    "submission.index = submission['timestamp']\n",
    "submission.loc[CHECK_TS,'attack'] = LABELS\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측한 결과를 저장하여 제출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('tttwo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Copyright 2020. ETRI부설국가보안기술연구소. All rights reserved.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
