{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "good_data = pd.read_csv(\"./dataset/good.csv\")\n",
    "bad_data = pd.read_csv(\"./dataset/bad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data = good_data.astype(int)\n",
    "bad_data = bad_data.astype(int)\n",
    "\n",
    "if os.path.exists(f'./dataset/fix_good_datas') and os.path.exists(f'./dataset/fix_bad_data') and os.path.exists(f'./dataset/drop_cols'):\n",
    "    fix_good_data = pickle.load(open(f'./fix_good_data','rb'))\n",
    "    fix_bad_data = pickle.load(open(f'./fix_bad_data','rb'))\n",
    "    drop_cols = pickle.load(open(f'./drop_cols','rb'))\n",
    "    \n",
    "else:\n",
    "\n",
    "    drop_cols = ['Unnamed: 0', '.', '+', '-',  '/', ',', '및', '은', '을', '의', '첫', '하기', '를', '3', '된', '매', \n",
    "                 '10', '5', '에', '에서', '완료', '!', '과', '있습니다', '만', '1', '8', '50', '는', '가', '고', '가장',\n",
    "                  '=', '2', '중','한', '하고', '4', '위', ')', '(', '100','30', '?', '하여', 'ㄴ', '것', '입니다', '많은',\n",
    "                  '합니다', '6', '시', '모든', '다', '와', '곳', '하는', '도', '적', '인', '할', '즈', '_', '경우',\n",
    "                  '우리', '일', '더', '9', '7', '0', '수', '들', ':', ']', '[', '으로', '없는', '&', '등', '로', '있는',\n",
    "                   '이', '충', '|', '\\'', '\\'', '\\\"', '경기', '저희', '호텔', '365']\n",
    "    for col in bad_data.columns:\n",
    "\n",
    "        vacuum_check = col.strip()\n",
    "\n",
    "        if bad_data[col].sum() < 5000 or len(vacuum_check) == 0:\n",
    "            drop_cols.append(col)\n",
    "\n",
    "    fix_good_data = good_data.drop(['Unnamed: 0.1'], axis=1)\n",
    "    fix_good_data = fix_good_data.drop(drop_cols, 1)\n",
    "    fix_bad_data = bad_data.drop(drop_cols, 1)\n",
    "    \n",
    "    fix_good_data['label'] = 0\n",
    "    fix_bad_data['label'] = 1\n",
    "\n",
    "    pickle.dump(fix_good_data, open(f'./dataset/fix_good_data','wb'))\n",
    "    pickle.dump(fix_bad_data, open(f'./dataset/fix_bad_data','wb'))\n",
    "    pickle.dump(drop_cols, open(f'./dataset/drop_cols','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 나누기 학습용 90% 테스트용 10%\n",
    "good_train = fix_good_data.sample(frac=0.9)\n",
    "good_test = fix_good_data.drop(good_train.index)\n",
    "\n",
    "bad_train = fix_bad_data.sample(frac=0.9)\n",
    "bad_test = fix_bad_data.drop(bad_train.index)\n",
    "\n",
    "train = pd.concat([good_train, bad_train], axis=0)\n",
    "test = pd.concat([good_test, bad_test], axis=0)\n",
    "\n",
    "# Shuffle\n",
    "train = train.sample(frac=1)\n",
    "test = test.sample(frac=1)\n",
    "\n",
    "x_train = train.iloc[:, :-1].to_numpy()\n",
    "y_train = train.iloc[:, -1:].to_numpy()\n",
    "\n",
    "x_test = test.iloc[:, :-1].to_numpy()\n",
    "y_test = test.iloc[:, -1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
